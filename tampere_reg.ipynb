{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df_train_filtered = pd.read_pickle('./data/df_train_filtered.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df_train_filtered.drop('Hinta', axis=1)\n",
    "y = df_train_filtered['Hinta']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, stratify=df_train_filtered['Kaupunginosa'], random_state=42)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler, StandardScaler, MinMaxScaler \n",
    "\n",
    "# Skaalataan numeeriset muuttujat\n",
    "robust_scaler = RobustScaler()\n",
    "std_scaler = StandardScaler()\n",
    "minmax_scaler = MinMaxScaler()\n",
    "df_train_NN = df_train_filtered.copy()\n",
    "df_train_NN[['Pituusaste', 'Leveysaste']] = minmax_scaler.fit_transform(df_train_NN[['Pituusaste', 'Leveysaste']])\n",
    "df_train_NN['Rv'] = minmax_scaler.fit_transform(df_train_NN[['Rv']])\n",
    "df_train_NN['m2'] = minmax_scaler.fit_transform(df_train_NN[['m2']])\n",
    "\n",
    "# One hot koodataan kategoriset muuttujat\n",
    "df_hot = pd.get_dummies(df_train_NN['Kaupunginosa'], prefix='Kaupunginosa').astype('int')\n",
    "df_train_NN = pd.concat([df_train_NN, df_hot], axis=1)\n",
    "\n",
    "df_hot = pd.get_dummies(df_train_NN['kerros'], prefix='kerros').astype('int')\n",
    "df_train_NN = pd.concat([df_train_NN, df_hot], axis=1)\n",
    "\n",
    "df_hot = pd.get_dummies(df_train_NN['max_kerros'], prefix='max_kerros').astype('int')\n",
    "df_train_NN = pd.concat([df_train_NN, df_hot], axis=1)\n",
    "\n",
    "df_hot = pd.get_dummies(df_train_NN['Kunto'], prefix='Kunto').astype('int')\n",
    "df_train_NN = pd.concat([df_train_NN, df_hot], axis=1)\n",
    "\n",
    "df_hot = pd.get_dummies(df_train_NN['Hissi'], prefix='Hissi').astype('int')\n",
    "df_train_NN = pd.concat([df_train_NN, df_hot], axis=1)\n",
    "\n",
    "df_hot = pd.get_dummies(df_train_NN['Asunnon tyyppi'], prefix='Asunnon tyyppi').astype('int')\n",
    "df_train_NN = pd.concat([df_train_NN, df_hot], axis=1)\n",
    "\n",
    "df_hot = pd.get_dummies(df_train_NN[\"Talot.\"], prefix='Talot.').astype('int')\n",
    "df_train_NN = pd.concat([df_train_NN, df_hot], axis=1)\n",
    "\n",
    "\n",
    "df_train_NN.drop(['Kaupunginosa', 'kerros', 'max_kerros', 'Kunto', 'Hissi', 'Asunnon tyyppi', \"Talot.\"], axis=1, inplace=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Muodostetaan X ja y sekä jaetaan data harjoitus- ja testijoukkoihin\n",
    "\n",
    "X = df_train_NN.drop('Hinta', axis=1)\n",
    "y = df_train_NN['Hinta']\n",
    "\n",
    "X = X.to_numpy()\n",
    "y = y.to_numpy().astype('float32')\n",
    "\n",
    "X_train_NN, X_test_NN, y_train_NN, y_test_NN = train_test_split(X, y, test_size=0.1, random_state=42, stratify=df_train_filtered['Kaupunginosa'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from keras import regularizers, layers, optimizers, initializers\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau, TerminateOnNaN\n",
    "import time \n",
    "from optuna.integration import TFKerasPruningCallback\n",
    "import os \n",
    "import pickle \n",
    "from datetime import timedelta\n",
    "\n",
    "\n",
    "# Haun nimi\n",
    "study_name = 'rmsle5_random_2503'\n",
    "# Montako osittelua käytettiin\n",
    "folds = 5\n",
    "# Montako epochia kullekin osittelulle\n",
    "epochs_search = 100\n",
    "# Montako satunnaista hakua kieroksella\n",
    "num_random = 42\n",
    "# Montako TPE hakua kieroksella\n",
    "num_tpe = 0\n",
    "\n",
    "# Aika sekuntteina jota hakuun käytetän\n",
    "max_search_time = 36000\n",
    "# Neuroneiden maksimimäärä \n",
    "max_units = 512\n",
    "\n",
    "def rmsle_loss(y_true, y_pred):\n",
    "    # Asetetaan suuri rangaistusarvo, jos y_pred sisältää arvon nolla tai alle\n",
    "    penalty = tf.constant(1e5, dtype=tf.float32)\n",
    "    \n",
    "    # Maski, joka on tosi, kun y_pred on > 0\n",
    "    valid_mask = tf.math.greater(y_pred, 0.0)\n",
    "    \n",
    "    # Käytä maskia valitsemaan joko oikea RMSLE laskenta tai suuri rangaistus\n",
    "    safe_y_pred = tf.where(valid_mask, y_pred, penalty)\n",
    "    \n",
    "    # Laske RMSLE vain, jos y_pred on suurempi kuin 0, muuten palauta rangaistus\n",
    "    rmsle = tf.sqrt(tf.reduce_mean(tf.square(tf.math.log1p(safe_y_pred) - tf.math.log1p(y_true))))\n",
    "    \n",
    "    # Palauta suuri rangaistus, jos y_pred sisälsi nollan tai negatiivisen arvon\n",
    "    return tf.where(tf.reduce_any(~valid_mask), penalty, rmsle)\n",
    "\n",
    "\n",
    "def create_model(trial):\n",
    "        \n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.layers.InputLayer(input_shape=(X_train_NN.shape[1],)))\n",
    "    \n",
    "    num_units = trial.suggest_int(f'n_units_0', 4, 512, log=True)\n",
    "    dropout_rate = trial.suggest_float(f'dropout_0', 0.0, 0.5)\n",
    "    kernel_regularizer=regularizers.l1_l2(\n",
    "            l1= trial.suggest_float(f'l1_reg_0', 1e-6, 1, log=True),\n",
    "            l2= trial.suggest_float(f'l2_reg_0', 1e-6, 1, log=True)\n",
    "        )\n",
    "    activation = trial.suggest_categorical(f'activation_0', ['relu', 'tanh', 'selu', 'linear', 'sigmoid', 'elu'])    \n",
    "    model.add(keras.layers.Dense(num_units, activation=activation, kernel_regularizer=kernel_regularizer))    \n",
    "    model.add(keras.layers.Dropout(rate=dropout_rate))\n",
    "\n",
    "    num_units = trial.suggest_int(f'n_units_1', 4, 256, log=True)\n",
    "    dropout_rate = trial.suggest_float(f'dropout_1', 0.0, 0.5)\n",
    "    kernel_regularizer=regularizers.l1_l2(\n",
    "            l1= trial.suggest_float(f'l1_reg_1', 1e-6, 1, log=True),\n",
    "            l2= trial.suggest_float(f'l2_reg_1', 1e-6, 1, log=True)\n",
    "        )\n",
    "    activation = trial.suggest_categorical(f'activation_1', ['relu', 'tanh', 'selu', 'linear', 'sigmoid', 'elu'])    \n",
    "    model.add(keras.layers.Dense(num_units, activation=activation, kernel_regularizer=kernel_regularizer))    \n",
    "    model.add(keras.layers.Dropout(rate=dropout_rate))\n",
    "    \n",
    "    num_last = trial.suggest_int('n_units_last', 1, 32)\n",
    "    dropout_last = trial.suggest_float('dropout_last', 0.0, 0.5)\n",
    "    activation_last = trial.suggest_categorical('activation_last', ['relu', 'tanh', 'selu', 'linear', 'sigmoid', 'elu'])\n",
    "    kernel_regularizer_last = regularizers.l1_l2( \n",
    "        l1= trial.suggest_float('l1_reg_last', 1e-6, 1, log=True),\n",
    "        l2= trial.suggest_float('l2_reg_last', 1e-6, 1, log=True)\n",
    "    )\n",
    "    model.add(keras.layers.Dense(num_last, activation=activation_last, kernel_regularizer=kernel_regularizer_last))        \n",
    "    model.add(keras.layers.Dropout(rate=dropout_last))\n",
    "    model.add(keras.layers.Dense(1, activation='linear')) \n",
    "    \n",
    "    # Optimisaattorin ja oppimisnopeuden valinta\n",
    "    optimizer_options = ['adam', 'rmsprop', 'Nadam', 'adamax', 'Adagrad', 'Adadelta']\n",
    "    optimizer_selected = trial.suggest_categorical('optimizer', optimizer_options)\n",
    "    learning_rate = trial.suggest_float('lr', 1e-4, 1.0, log=True)\n",
    "    \n",
    "    if optimizer_selected == 'adam':\n",
    "        optimizer = optimizers.Adam(learning_rate=learning_rate)\n",
    "    elif optimizer_selected == 'rmsprop':\n",
    "        optimizer = optimizers.RMSprop(learning_rate=learning_rate)\n",
    "    elif optimizer_selected == 'Nadam':\n",
    "        optimizer = optimizers.Nadam(learning_rate=learning_rate)\n",
    "    elif optimizer_selected == 'Adagrad':\n",
    "        optimizer = optimizers.Adagrad(learning_rate=learning_rate)\n",
    "    elif optimizer_selected == 'Adadelta':\n",
    "        optimizer = optimizers.Adadelta(learning_rate=learning_rate)\n",
    "    else:\n",
    "        optimizer = optimizers.Adamax(learning_rate=learning_rate)\n",
    "\n",
    "    model.compile(optimizer=optimizer, loss=rmsle_loss, metrics=['mse', 'mae'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "def objective(trial):\n",
    "\n",
    "    model = create_model(trial)\n",
    "    batch_size = trial.suggest_int('batch_size', 16, 128, log=True)    \n",
    "    callbacks = [TFKerasPruningCallback(trial, 'val_loss'),\n",
    "                 ReduceLROnPlateau('val_loss', patience=5, factor=0.7), \n",
    "                 TerminateOnNaN()]\n",
    "\n",
    "    history = model.fit(X_train_b, y_train_b, epochs=epochs_search, validation_data=(X_val_b, y_val_b) ,batch_size=batch_size, verbose=0, callbacks=callbacks)\n",
    "    val_loss = np.min(history.history['val_loss'])\n",
    "    \n",
    "    return val_loss\n",
    "\n",
    "\n",
    "####\n",
    "\n",
    "total_time_start = time.time()  \n",
    "search_time_start = time.time() \n",
    "num_completed_trials = 0\n",
    "search_rounds = 0\n",
    "time_taken = 0\n",
    "while time_taken < max_search_time:\n",
    "        \n",
    "    fold = 0 \n",
    "    kf = KFold(n_splits=folds)\n",
    "    \n",
    "    time_fold_start = time.time()    \n",
    "    for train_index, val_index in kf.split(X_train_NN):\n",
    "\n",
    "        print('-------------------')\n",
    "        print(f\"Starting fold {fold} search...\")\n",
    "        X_train_b, X_val_b = X_train_NN[train_index], X_train_NN[val_index]    \n",
    "        y_train_b, y_val_b = y_train_NN[train_index], y_train_NN[val_index]\n",
    "\n",
    "        fold_name = f'{study_name}_{fold}'\n",
    "       \n",
    "        study = optuna.create_study(direction='minimize',\n",
    "                                    pruner=optuna.pruners.HyperbandPruner(min_resource=5),\n",
    "                                    study_name=fold_name,\n",
    "                                    storage=f'sqlite:///tampere_reg.db',\n",
    "                                    load_if_exists=True                                 \n",
    "                                    )\n",
    "\n",
    "        fold_time = time.time()    \n",
    "\n",
    "        fold_random = time.time()\n",
    "        # # study.sampler = optuna.samplers.RandomSampler()\n",
    "        study.sampler = optuna.samplers.QMCSampler(warn_independent_sampling = False) # TODO tämä testiin, vaikutti paljon paremmalta kuin random \n",
    "        print(f'Random search for fold {fold}...')\n",
    "        study.optimize(objective, n_trials=num_random)\n",
    "        print(f'Time taken for random search: {str(timedelta(seconds=(time.time() - fold_random)))}')\n",
    "\n",
    "        # fold_tpe = time.time()  \n",
    "        # study.sampler = optuna.samplers.TPESampler(n_startup_trials=0)\n",
    "        # print(f'TPE search for fold {fold}...')\n",
    "        # study.optimize(objective, n_trials=num_tpe)\n",
    "        # print(f'Time taken for TPE search: {str(timedelta(seconds=(time.time() - fold_tpe)))}')\n",
    "\n",
    "        num_completed_trials += num_random + num_tpe\n",
    "        print('-------------------')\n",
    "        print(f'Finished fold {fold} search.')\n",
    "        print(f\"Time taken for this fold: {str(timedelta(seconds=(time.time() - fold_time)))}\")                \n",
    "        print(f'Fold {fold} best value so far: {study.best_value}')\n",
    "        print(f'Mean time for one trial this fold: {str(timedelta(seconds=(time.time() - fold_time) / (num_random + num_tpe)))}')\n",
    "\n",
    "        fold += 1\n",
    "    search_rounds += 1\n",
    "    \n",
    "    time_taken = time.time() - search_time_start\n",
    "    \n",
    "    print(f'\\n# Completed search round: {search_rounds} #')\n",
    "    print(f'Time taken for all folds this round: {str(timedelta(seconds=(time.time() - time_fold_start)))}')\n",
    "    print(f'Total time taken for search: {str(timedelta(seconds=(time.time() - search_time_start)))}')\n",
    "    print(f'Made trials this far: {num_completed_trials}')\n",
    "    print(f\"Current mean time for one trial: {str(timedelta(seconds=(time.time() - search_time_start) / num_completed_trials))}\\n\")\n",
    "\n",
    "####\n",
    "\n",
    "####\n",
    "\n",
    "# num_tpe = 42\n",
    "    # num_random = 0\n",
    "    # max_search_time = 7200\n",
    "    \n",
    "# while time_taken < max_search_time:\n",
    "        \n",
    "#     fold = 0 \n",
    "#     kf = KFold(n_splits=folds)\n",
    "    \n",
    "#     time_fold_start = time.time()    \n",
    "#     for train_index, val_index in kf.split(X_train_NN):\n",
    "\n",
    "#         print('-------------------')\n",
    "#         print(f\"Starting fold {fold} search...\")\n",
    "#         X_train_b, X_val_b = X_train_NN[train_index], X_train_NN[val_index]    \n",
    "#         y_train_b, y_val_b = y_train_NN[train_index], y_train_NN[val_index]\n",
    "\n",
    "#         fold_name = f'{study_name}_{fold}'\n",
    "       \n",
    "#         study = optuna.create_study(direction='minimize',\n",
    "#                                     pruner=optuna.pruners.HyperbandPruner(min_resource=20),\n",
    "#                                     study_name=fold_name,\n",
    "#                                     storage=f'sqlite:///tampere_reg.db',\n",
    "#                                     load_if_exists=True                                 \n",
    "#                                     )\n",
    "\n",
    "#         fold_time = time.time()    \n",
    "\n",
    "#         # fold_random = time.time()\n",
    "#         # study.sampler = optuna.samplers.RandomSampler()\n",
    "#         # print(f'Random search for fold {fold}...')\n",
    "#         # study.optimize(objective, n_trials=num_random)\n",
    "#         # print(f'Time taken for random search: {str(timedelta(seconds=(time.time() - fold_random)))}')\n",
    "\n",
    "#         fold_tpe = time.time()  \n",
    "#         study.sampler = optuna.samplers.TPESampler(n_startup_trials=0)\n",
    "#         print(f'TPE search for fold {fold}...')\n",
    "#         study.optimize(objective, n_trials=num_tpe)\n",
    "#         print(f'Time taken for TPE search: {str(timedelta(seconds=(time.time() - fold_tpe)))}')\n",
    "\n",
    "#         num_completed_trials += num_random + num_tpe\n",
    "#         print('-------------------')\n",
    "#         print(f'Finished fold {fold} search.')\n",
    "#         print(f\"Time taken for this fold: {str(timedelta(seconds=(time.time() - fold_time)))}\")                \n",
    "#         print(f'Fold {fold} best value so far: {study.best_value}')\n",
    "#         print(f'Mean time for one trial this fold: {str(timedelta(seconds=(time.time() - fold_time) / (num_random + num_tpe)))}')\n",
    "\n",
    "#         fold += 1\n",
    "#     search_rounds += 1\n",
    "    \n",
    "#     time_taken = time.time() - search_time_start\n",
    "    \n",
    "#     print(f'\\n# Completed search round: {search_rounds} #')\n",
    "#     print(f'Time taken for all folds this round: {str(timedelta(seconds=(time.time() - time_fold_start)))}')\n",
    "#     print(f'Total time taken for search: {str(timedelta(seconds=(time.time() - search_time_start)))}')\n",
    "#     print(f'Made trials this far: {num_completed_trials}')\n",
    "#     print(f\"Current mean time for one trial: {str(timedelta(seconds=(time.time() - search_time_start) / num_completed_trials))}\\n\")\n",
    "\n",
    "###\n",
    "\n",
    "print('='*20)    \n",
    "print(f'Finished search.')    \n",
    "print(f'Total time taken for all folds: {str(timedelta(seconds=(time.time() - search_time_start)))}')\n",
    "print(f'Made {num_completed_trials} trials in total.')\n",
    "print(f\"Mean time for one trial: {str(timedelta(seconds=(time.time() - search_time_start) / num_completed_trials))}\")\n",
    "print('='*20)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# for fold in range(folds):\n",
    "    \n",
    "#     study_name_fold = f'{study_name}_{fold}'\n",
    "#     print('*'*50)\n",
    "#     print(f'{study_name_fold}')\n",
    "#     print('*'*50)\n",
    "#     study = optuna.load_study(study_name=study_name_fold, storage='sqlite:///tampere_reg.db')\n",
    "    \n",
    "#     # fig = optuna.visualization.plot_param_importances(study)\n",
    "#     # fig.update_layout(title=f'Param Importance for Fold {fold}', width=1800, height=1800)\n",
    "#     # fig.show()\n",
    "\n",
    "#     # fig = optuna.visualization.plot_slice(study)\n",
    "#     # fig.update_layout(title=f'Slice for Fold {fold}', width=800, height=800)\n",
    "#     # fig.show()\n",
    "    \n",
    "#     fig = optuna.visualization.plot_parallel_coordinate(study)\n",
    "#     fig.update_layout(width=2000, height=2000)\n",
    "#     fig.show()\n",
    "\n",
    "#     # fig = optuna.visualization.plot_contour(study, params=['n_units_0', 'n_units_1', 'n_units_last'])\n",
    "#     # fig.update_layout(width=1800, height=1800)\n",
    "#     # fig.show()\n",
    "\n",
    "#     # fig = optuna.visualization.plot_contour(study)\n",
    "#     # fig.update_layout(width=3600, height=3600)\n",
    "#     # fig.show()\n",
    "\n",
    "#     # fig = optuna.visualization.plot_edf(study)\n",
    "#     # fig.update_layout(width=1800, height=1800)\n",
    "#     # fig.show()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import timedelta\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "import optuna\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from keras import regularizers, layers, optimizers, initializers\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau, TerminateOnNaN\n",
    "import time \n",
    "import os \n",
    "\n",
    "\n",
    "folds = 5\n",
    "# Montako epochia kullekin parhaalle sovitetaan malli\n",
    "epochs_best_fit = 500\n",
    "# Montako paras otetaan mukaan osittelusta\n",
    "num_best = 6\n",
    "# Montako kertaa kullekin parhaalle sovitetaan malli\n",
    "num_best_fits = 1\n",
    "\n",
    "best_optuna_models = []\n",
    "best_val_scores = []\n",
    "best_optuna_trials = [] \n",
    "\n",
    "kf = KFold(n_splits=folds)\n",
    "fold_num = 0\n",
    "fitting_search_start = time.time()\n",
    "\n",
    "for train_index, val_index in kf.split(X_train_NN):\n",
    "\n",
    "    best_fitting_time = time.time()\n",
    "    print(f\"Fold {fold_num} Best best trial fitting...\")\n",
    "\n",
    "    X_train_b, X_val_b = X_train_NN[train_index], X_train_NN[val_index]    \n",
    "    y_train_b, y_val_b = y_train_NN[train_index], y_train_NN[val_index]\n",
    "    \n",
    "    fold_name = f'{study_name}_{fold_num}'\n",
    "       \n",
    "    study = optuna.create_study(                                \n",
    "                                study_name=fold_name,\n",
    "                                storage=f'sqlite:///tampere_reg.db',\n",
    "                                load_if_exists=True\n",
    "                                )\n",
    "\n",
    "    valid_trials = [trial for trial in study.trials if trial.value is not None]\n",
    "    sorted_trials = sorted(valid_trials, key=lambda trial: trial.value)\n",
    "    best_trials = sorted_trials[:num_best]\n",
    "    best_val = np.inf\n",
    "    best_model = None\n",
    "\n",
    "    print('='*30)\n",
    "    print(f'Fitting best trials for fold {fold_num}...')\n",
    "    fitting_fold_best_start = time.time()\n",
    "    \n",
    "    for trial in best_trials:\n",
    "\n",
    "        for fit_num in range(num_best_fits):\n",
    "            \n",
    "            print('-'*30)\n",
    "            print(f\"Trial ID: {trial.number}, Value: {trial.value}, fit number: {fit_num}\")\n",
    "\n",
    "            checkpoint_filepath = f'./NN_search/optuna_search_checkpoint.h5'\n",
    "            model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "                filepath=checkpoint_filepath,\n",
    "                save_weights_only=True,\n",
    "                monitor='val_loss',\n",
    "                mode='min',\n",
    "                save_best_only=True)\n",
    "\n",
    "            best_callback = [model_checkpoint_callback,                  \n",
    "                            ReduceLROnPlateau('val_loss', patience=10, factor=0.8), \n",
    "                            TerminateOnNaN(),\n",
    "                            EarlyStopping(monitor='val_loss', patience=100, verbose=1)\n",
    "                        ]\n",
    "\n",
    "\n",
    "            model = create_model(trial)\n",
    "            model.fit(X_train_b, y_train_b, epochs=epochs_best_fit, validation_data=(X_val_b, y_val_b), batch_size=trial.params['batch_size'], verbose=0, callbacks=best_callback)\n",
    "            model.load_weights(checkpoint_filepath)\n",
    "\n",
    "            predictions = model.predict(X_val_b, verbose=0)\n",
    "            mse = mean_squared_error(y_val_b, predictions)\n",
    "            mae = mean_absolute_error(y_val_b, predictions)\n",
    "            r2 = r2_score(y_val_b, predictions)\n",
    "            rmsle = rmsle_score(y_val_b, predictions)\n",
    "\n",
    "                        \n",
    "            print(f'MSE:{mse:.5f}\\nMAE:{mae:.5f}\\nRMSLE:{rmsle:.5f}\\nR2:{r2:.5f}')\n",
    "\n",
    "            if rmsle < best_val:\n",
    "                best_model = model\n",
    "                best_val = rmsle\n",
    "                best_trial_num = trial.number\n",
    "                best_trial = trial\n",
    "                print(f'*** New best model for fold {fold_num} is Trial {best_trial_num} with RMSLE {best_val} ***')\n",
    "                print(f'Best trial hyperparameters: {trial.params}')\n",
    "    \n",
    "    if best_model is not None:\n",
    "\n",
    "        best_optuna_models.append(best_model)\n",
    "        best_val_scores.append(best_val)\n",
    "        best_optuna_trials.append(best_trial)\n",
    "        print('*'*40)\n",
    "        print(f\"Best model for fold {fold_num} RMSLE: {best_val}\\nTrial number: {best_trial_num}\\nHyperparameters: {best_trial.params}\")\n",
    "        print(f\"Time taken for best fitting in fold {fold_num}: {str(timedelta(seconds=(time.time() - best_fitting_time)) )}\")\n",
    "        print('*'*40)\n",
    "\n",
    "    fold_num += 1\n",
    "\n",
    "print('*'*40)\n",
    "print(f'Best models fitting time total:', str(timedelta(seconds=(time.time() - fitting_search_start))))\n",
    "print(f\"Total time taken for search and fitting best models: {str(timedelta(seconds=(time.time() - total_time_start)))}\")\n",
    "print('*'*40)   \n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "for i, (model, score) in enumerate(zip(best_optuna_models, best_val_scores)):\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    directory = f\"./NN_search/{study_name}_foldmodel{i}_score_{score:.4f}_{timestamp}.h5\"\n",
    "    print(f\"Saving model {i} with score {score:.4f} to {directory}\")\n",
    "    model.save(directory)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, model in enumerate(best_optuna_models):\n",
    "    print(f\"\\nModel {idx} Summary:\")\n",
    "    # model.summary()\n",
    "    \n",
    "    # Testaa mallia testidatalla\n",
    "    predictions = model.predict(X_test_NN, verbose = 0)\n",
    "    mse = mean_squared_error(y_test_NN, predictions)\n",
    "    mae = mean_absolute_error(y_test_NN, predictions)\n",
    "    r2 = r2_score(y_test_NN, predictions)\n",
    "    rmsle = rmsle_score(y_test_NN, predictions)\n",
    "    \n",
    "    print(f\"\\nModel {idx} Performance on Test Data:\")\n",
    "    print(f\"MSE: {mse:.3f}\")\n",
    "    print(f\"MAE: {mae:.3f}\")\n",
    "    print(f\"R2: {r2:.3f}\")\n",
    "    print(f\"RMSLE: {rmsle:.3f}\")\n",
    "    print(\"*\"*40)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import timedelta\n",
    "import time\n",
    "from tensorflow.keras.models import Model\n",
    "import glob\n",
    "import pickle\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "time_started_xgb = time.time()\n",
    "\n",
    "num_of_trials = 720\n",
    "\n",
    "# Kerätään ensin kaikkien mallien ominaisuusvektorit\n",
    "X_train_features_list = []\n",
    "X_test_features_list = []\n",
    "features_names_list = []\n",
    "\n",
    "best_optuna_models = []\n",
    "\n",
    "def rmsle_loss(y_true, y_pred):\n",
    "    penalty = tf.constant(1e5, dtype=tf.float32)\n",
    "    valid_mask = tf.math.greater(y_pred, 0.0)\n",
    "    safe_y_pred = tf.where(valid_mask, y_pred, penalty)\n",
    "    rmsle = tf.sqrt(tf.reduce_mean(tf.square(tf.math.log1p(safe_y_pred) - tf.math.log1p(y_true))))\n",
    "    return tf.where(tf.reduce_any(~valid_mask), penalty, rmsle)\n",
    "\n",
    "# Kun lataat mallin, määritä mukautettu häviöfunktio custom_objects-parametrissa\n",
    "custom_objects = {\"rmsle_loss\": rmsle_loss}\n",
    "\n",
    "model_best_vals = []\n",
    "\n",
    "# for fold_num in [1]:\n",
    "for fold_num in range(folds): # TODO testiä parhailla malleilla\n",
    "    pattern = f\"./NN_search/{study_name}_foldmodel{fold_num}_score_*.h5\"  # Oletetaan, että mallit on tallennettu .h5-muodossa\n",
    "    model_files = glob.glob(pattern)\n",
    "    \n",
    "    # Etsi suurin score kunkin foldin mallitiedostoista\n",
    "    best_score = float('inf')\n",
    "    best_model_file = None\n",
    "    for model_file in model_files:\n",
    "        score_part = model_file.split('_score_')[1]  # Erottaa score osan tiedostonimestä        \n",
    "        score = float(score_part.split('_')[0])  # Muuttaa scoren float-arvoksi\n",
    "        if score < best_score:\n",
    "            best_score = score\n",
    "            best_model_file = model_file\n",
    "\n",
    "    model_best_vals.append(best_score)    \n",
    "    # Lataa parhaan mallin tiedosto\n",
    "    if best_model_file:\n",
    "        best_model = load_model(best_model_file, custom_objects=custom_objects)\n",
    "        best_optuna_models.append(best_model)\n",
    "        print(f\"Loaded best model for fold {fold_num} from {best_model_file} with score {best_score:.4f}\")\n",
    "    else:\n",
    "        print(f\"No model files found for fold {fold_num} matching pattern {pattern}\")\n",
    "\n",
    "\n",
    "# best_models_per_fold-listas\n",
    "\n",
    "original_feature_names = list(X_train.columns) \n",
    "\n",
    "for idx, model in enumerate(best_optuna_models):\n",
    "    feature_extractor = Model(inputs=model.inputs, outputs=model.layers[-2].output)\n",
    "    X_train_features = feature_extractor.predict(X_train_NN)\n",
    "    X_test_features = feature_extractor.predict(X_test_NN)\n",
    "    \n",
    "    X_train_features_list.append(X_train_features)\n",
    "    X_test_features_list.append(X_test_features)\n",
    "\n",
    "    print(f'Model train feature shape: {X_train_features.shape}')\n",
    "    print(f'Model test feature shape: {X_test_features.shape}')\n",
    "\n",
    "    num_features = X_train_features.shape[1]\n",
    "    model_feature_names = [f\"model_{idx}_feature_{feature_idx}\" for feature_idx in range(num_features)]\n",
    "    features_names_list.extend(model_feature_names)\n",
    "\n",
    "combined_feature_names = original_feature_names + features_names_list\n",
    "\n",
    "# Yhdistetään ominaisuusvektorit\n",
    "X_train_combined = np.concatenate(X_train_features_list, axis=1)\n",
    "X_test_combined = np.concatenate(X_test_features_list, axis=1)\n",
    "\n",
    "X_train_combined = np.concatenate([X_train_combined, X_train], axis=1)   \n",
    "X_test_combined = np.concatenate([X_test_combined, X_test], axis=1)\n",
    "\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "\n",
    "#### Ei valintaa \n",
    "X_train_combined_selected = X_train_combined\n",
    "X_test_combined_selected = X_test_combined\n",
    "selected_features_names = combined_feature_names\n",
    "\n",
    "\n",
    "##### mutual_info_regression Valinta\n",
    "\n",
    "# from sklearn.feature_selection import SelectKBest, f_regression, mutual_info_regression\n",
    "\n",
    "# max_feature = X_train_combined.shape[1] // 2\n",
    "\n",
    "# selector = SelectKBest(mutual_info_regression, k=max_feature)\n",
    "\n",
    "# X_train_combined_selected = selector.fit_transform(X_train_combined, y_train)\n",
    "# X_test_combined_selected = selector.transform(X_test_combined)\n",
    "\n",
    "# selected_indices = selector.get_support(indices=True)\n",
    "# selected_features_names = np.array(combined_feature_names)[selected_indices]\n",
    "# selected_features_scores = selector.scores_[selected_indices]\n",
    "\n",
    "# print(\"Selected features and their scores:\")\n",
    "# for name, score in zip(selected_features_names, selected_features_scores):\n",
    "#     print(f\"{name}: {score}\")\n",
    "\n",
    "# selected_features_names = selected_features_names.tolist()\n",
    "\n",
    "# print(f'X_train_combined shape: {X_train_combined.shape}')\n",
    "# print(f'X_train_combined_selected shape: {X_train_combined_selected.shape}')\n",
    "\n",
    "# print(f'X_test_combined shape: {X_test_combined.shape}')\n",
    "# print(f'X_test combined selected shape: {X_test_combined_selected.shape}')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ##### PCA valinta\n",
    "\n",
    "\n",
    "\n",
    "# from sklearn.decomposition import PCA\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# # Oletetaan, että X_train_combined ja X_test_combined ovat datasi\n",
    "# # Ja combined_feature_names on alkuperäisten featureiden nimilista\n",
    "\n",
    "# # Skaalataan data\n",
    "# scaler = StandardScaler()\n",
    "# X_train_scaled = scaler.fit_transform(X_train_combined)\n",
    "# X_test_scaled = scaler.transform(X_test_combined)\n",
    "\n",
    "# # Sovellamme PCA:ta\n",
    "# pca = PCA(n_components=0.85) # tai voit määrittää n_components arvon eksplisiittisesti\n",
    "# X_train_combined_selected = pca.fit_transform(X_train_scaled)\n",
    "# X_test_combined_selected = pca.transform(X_test_scaled)\n",
    "\n",
    "# # Luodaan uudet feature-nimet pääkomponenteille\n",
    "# selected_features_names = [f\"PC{i+1}\" for i in range(X_train_combined_selected.shape[1])]\n",
    "\n",
    "# print(f\"Alkuperäinen featureiden määrä: {X_train_combined.shape[1]}\")\n",
    "# print(f\"Featureiden määrä PCA:n jälkeen: {X_train_combined_selected.shape[1]}\")\n",
    "\n",
    "# # Nyt sinulla on X_train_pca ja X_test_pca datat sekä niiden vastaavat feature-nimet\n",
    "# # Voit jatkaa näiden käyttämistä mallisi koulutukseen\n",
    "\n",
    "\n",
    "\n",
    "#####\n",
    "\n",
    "def rmsle(y_true, y_pred):\n",
    "    if np.any(y_pred <= 0):\n",
    "        return 1e6\n",
    "    return np.sqrt(np.mean(np.square(np.log1p(y_pred) - np.log1p(y_true))))\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "\n",
    "\n",
    "max_feature = X_train_combined.shape[1]\n",
    "\n",
    "def objective(trial):\n",
    "    # Määritetään parametrit, jotka optimoidaan\n",
    "    param = {\n",
    "        'tree_method': 'hist',          \n",
    "        'objective': trial.suggest_categorical('objective', ['reg:squarederror', 'reg:absoluteerror']),        \n",
    "        'max_depth': trial.suggest_int('max_depth', 1, 10),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 1e-5, 1.0, log=True),\n",
    "        'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
    "        'gamma': trial.suggest_float('gamma', 0, 10),\n",
    "        'reg_alpha': trial.suggest_float('reg_alpha', 0, 1),\n",
    "        'reg_lambda': trial.suggest_float('reg_lambda', 1, 10)        \n",
    "    }\n",
    "    num_boost_round = trial.suggest_int('num_boost_round', 10, 142)\n",
    "\n",
    "    # K-fold cross-validation\n",
    "    kf = KFold(n_splits=5)\n",
    "    rmsle_scores = []\n",
    "  \n",
    "    for train_index, val_index in kf.split(X_train_combined_selected):\n",
    "        X_train_k, X_val_k = X_train_combined_selected[train_index], X_train_combined_selected[val_index]\n",
    "        y_train_k, y_val_k = y_train[train_index], y_train[val_index]\n",
    "\n",
    "        dtrain = xgb.DMatrix(X_train_k, label=y_train_k, feature_names=selected_features_names)\n",
    "        dval = xgb.DMatrix(X_val_k, label=y_val_k, feature_names=selected_features_names)\n",
    "\n",
    "        evals_result = {}\n",
    "        bst = xgb.train(param, dtrain, num_boost_round=num_boost_round, evals=[(dval, 'val')], evals_result=evals_result, verbose_eval=False, early_stopping_rounds=300)\n",
    "        # Käytä paras iteraatio määrä laskemaan ennusteet ja RMSLE\n",
    "        best_iteration = bst.best_iteration\n",
    "        preds = bst.predict(dval, iteration_range=(0, best_iteration + 1))\n",
    "        loss = rmsle(y_val_k, preds)\n",
    "        rmsle_scores.append(loss)\n",
    "\n",
    "    average_rmsle = np.mean(rmsle_scores)\n",
    "    return average_rmsle\n",
    "\n",
    "# study = optuna.create_study(direction='minimize', \n",
    "#                             storage='sqlite:///tampere_reg.db', \n",
    "#                             study_name='xgb_combined_selection_2503', # TODO muuta nimeä tarvittaessa\n",
    "#                             load_if_exists=False) \n",
    "\n",
    "study = optuna.create_study(direction='minimize')\n",
    "\n",
    "# study.sampler = optuna.samplers.RandomSampler()\n",
    "study.sampler = optuna.samplers.QMCSampler(warn_independent_sampling = False)\n",
    "print(f'Random sampling {num_of_trials} trials...')\n",
    "study.optimize(objective, n_trials=num_of_trials)\n",
    "study.sampler = optuna.samplers.TPESampler()\n",
    "print(f'TPE sampling {num_of_trials} trials...')\n",
    "study.optimize(objective, n_trials=num_of_trials)\n",
    "\n",
    "\n",
    "print(f'Time taken for XGBoost optimization: {str(timedelta(seconds=(time.time() - time_started_xgb)))}')\n",
    "print(f'Time taken for one trial: {str(timedelta(seconds=(time.time() - time_started_xgb) / (num_of_trials*2)))}')\n",
    "\n",
    "\n",
    "# Parhaiden parametrien tulostus ja mallin koulutus\n",
    "print(f\"Best val: {study.best_trial.value}\")\n",
    "print(f'Best params: {study.best_params}')\n",
    "\n",
    "dtrain = xgb.DMatrix(X_train_combined_selected, label=y_train, feature_names=selected_features_names)\n",
    "best_model = xgb.train(best_params, dtrain, num_boost_round=best_params['num_boost_round'])\n",
    "\n",
    "# Ennustukset ja evaluointi testidatalla\n",
    "dtest = xgb.DMatrix(X_test_combined_selected, label=y_test, feature_names=selected_features_names)\n",
    "predictions = best_model.predict(dtest)\n",
    "\n",
    "# Visualisoidaan ennustettuja arvoja verrattuna todellisiin arvoihin\n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.scatter(y_test, predictions, edgecolors=(0, 0, 0))\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--', lw=4)\n",
    "plt.xlabel('Measured')\n",
    "plt.ylabel('Predicted')\n",
    "plt.title('Measured vs. Predicted Values')\n",
    "plt.show()\n",
    "\n",
    "mse = mean_squared_error(y_test, predictions)\n",
    "mae = mean_absolute_error(y_test, predictions)\n",
    "r2 = r2_score(y_test, predictions)\n",
    "rmsle_val = rmsle(y_test, predictions)\n",
    "print(f\"MAE: {mae}, MSE: {mse}, R2: {r2}, RMSLE: {rmsle_val}\")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20, 30))\n",
    "xgb.plot_importance(best_model, importance_type='weight', ax=ax)\n",
    "ax.set_title('Feature Importance by Weight', fontsize=16)\n",
    "plt.show()\n",
    "\n",
    "# Asetetaan toisen kuvaajan koko\n",
    "fig, ax = plt.subplots(figsize=(20, 30))\n",
    "xgb.plot_importance(best_model, importance_type='gain', ax=ax)\n",
    "ax.set_title('Feature Importance by Gain', fontsize=16)\n",
    "plt.show()\n",
    "\n",
    "# Asetetaan kolmannen kuvaajan koko\n",
    "fig, ax = plt.subplots(figsize=(20, 30))\n",
    "xgb.plot_importance(best_model, importance_type='cover', ax=ax)\n",
    "ax.set_title('Feature Importance by Cover', fontsize=16)\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_train = []\n",
    "\n",
    "for idx, model in enumerate(best_optuna_models):\n",
    "    pred = model.predict(X_train_NN, verbose=0).flatten()\n",
    "    predictions_train.append(pred)\n",
    "\n",
    "predictions_test = []\n",
    "\n",
    "for idx, model in enumerate(best_optuna_models):\n",
    "    pred = model.predict(X_test_NN, verbose=0).flatten()\n",
    "    predictions_test.append(pred)\n",
    "\n",
    "\n",
    "print('Keskiarvo ')\n",
    "predictions_mean = np.mean(predictions_test, axis=0)\n",
    "mse = mean_squared_error(y_test, predictions_mean)\n",
    "mae = mean_absolute_error(y_test, predictions_mean)\n",
    "r2 = r2_score(y_test, predictions_mean)\n",
    "rmsle_val = rmsle(y_test, predictions_mean)  # Oletetaan että sinulla on rmsle funktio määritelty\n",
    "print(f\"MAE: {mae}, MSE: {mse}, R2: {r2}, RMSLE: {rmsle_val}\\n\\n\")\n",
    "\n",
    "print('Painotettu keskiarvo käänteisillä')\n",
    "total = sum(model_best_vals)\n",
    "weights = [x / total for x in model_best_vals]\n",
    "weighted_predictions = np.average(predictions_test, axis=0, weights=weights)\n",
    "mse = mean_squared_error(y_test, weighted_predictions)\n",
    "mae = mean_absolute_error(y_test, weighted_predictions)\n",
    "r2 = r2_score(y_test, weighted_predictions)\n",
    "rmsle_val = rmsle(y_test, weighted_predictions)  # Oletetaan että sinulla on rmsle funktio määritelty\n",
    "print(f\"MAE: {mae}, MSE: {mse}, R2: {r2}, RMSLE: {rmsle_val}\\n\\n\")\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Oletetaan, että `predictions` on lista, joka sisältää kunkin mallin ennusteet testidatasetille\n",
    "X_meta_train = np.stack(predictions_train, axis=1)\n",
    "X_meta_test = np.stack(predictions_test, axis=1)\n",
    "# Koulutetaan meta-malli\n",
    "meta_model = LinearRegression()\n",
    "meta_model.fit(X_meta_train, y_train)\n",
    "\n",
    "# Käytetään meta-mallia ennustamaan\n",
    "linear_predictions = meta_model.predict(X_meta_test)\n",
    "\n",
    "print('Linear meta')\n",
    "mse = mean_squared_error(y_test, linear_predictions)\n",
    "mae = mean_absolute_error(y_test, linear_predictions)\n",
    "r2 = r2_score(y_test, linear_predictions)\n",
    "rmsle_val = rmsle(y_test, linear_predictions)  # Oletetaan että sinulla on rmsle funktio määritelty\n",
    "print(f\"MAE: {mae}, MSE: {mse}, R2: {r2}, RMSLE: {rmsle_val}\\n\\n\")\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "print('SVM')\n",
    "X_train_svm = np.column_stack(predictions_train)\n",
    "X_test_svm = np.column_stack(predictions_test)\n",
    "\n",
    "svm_regressor = SVR(kernel='linear')\n",
    "svm_regressor.fit(X_train_svm, y_train)\n",
    "\n",
    "# Käytetään opetettua SVM-regressoria ennustamaan testidatan \"oikeat\" arvot\n",
    "predictions_svm = svm_regressor.predict(X_test_svm)\n",
    "\n",
    "# Arvioidaan mallin suorituskykyä\n",
    "mse = mean_squared_error(y_test, predictions_svm)\n",
    "mae = mean_absolute_error(y_test, predictions_svm)\n",
    "r2 = r2_score(y_test, predictions_svm)\n",
    "rmsle_val = rmsle(y_test, predictions_svm)\n",
    "print(f\"SVM MAE: {mae}, MSE: {mse}, R2: {r2}, RMSLE: {rmsle_val}\\n\\n\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "joda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
