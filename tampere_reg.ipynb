{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df_train_filtered = pd.read_pickle('./data/df_train_filtered.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Koska Talot. tyyppejä ei ole kovin montaa, niin yhdistetään ne kaupunginosan kanssa jonka mukaan tehdään testi data setti\n",
    "df_train_filtered['combined'] = df_train_filtered[['Kaupunginosa', 'Talot.']].astype(str).agg('-'.join, axis=1)\n",
    "counts = df_train_filtered['combined'].value_counts()\n",
    "df_train_filtered['combined'] = df_train_filtered['combined'].map(lambda x: 'other' if counts[x] < 2 else x)\n",
    "X = df_train_filtered.drop('Hinta', axis=1)\n",
    "y = df_train_filtered['Hinta']\n",
    "\n",
    "X_train, X_test, _ , _ = train_test_split(X, y, test_size=0.1, stratify=df_train_filtered['combined'], random_state=42)\n",
    "X_train.drop('combined', axis=1, inplace=True)\n",
    "X_test.drop('combined', axis=1, inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler, StandardScaler, MinMaxScaler \n",
    "\n",
    "# Skaalataan numeeriset muuttujat. Koska koordinaatit ja Rv sekä m2 ei ole mielestäni sellaisia, että pitäisi murehtia train ja test setin välillä vuotaisi tietoa, niin skaalataan ne kaikki yhdessä\n",
    "robust_scaler = RobustScaler()\n",
    "std_scaler = StandardScaler()\n",
    "minmax_scaler = MinMaxScaler()\n",
    "df_train_NN = df_train_filtered.copy()\n",
    "df_train_NN[['Pituusaste', 'Leveysaste']] = minmax_scaler.fit_transform(df_train_NN[['Pituusaste', 'Leveysaste']])\n",
    "df_train_NN['Rv'] = minmax_scaler.fit_transform(df_train_NN[['Rv']])\n",
    "df_train_NN['m2'] = minmax_scaler.fit_transform(df_train_NN[['m2']])\n",
    "\n",
    "# One hot koodataan kategoriset muuttujat\n",
    "df_hot = pd.get_dummies(df_train_NN['Kaupunginosa'], prefix='Kaupunginosa').astype('int')\n",
    "df_train_NN = pd.concat([df_train_NN, df_hot], axis=1)\n",
    "\n",
    "df_hot = pd.get_dummies(df_train_NN['kerros'], prefix='kerros').astype('int')\n",
    "df_train_NN = pd.concat([df_train_NN, df_hot], axis=1)\n",
    "\n",
    "df_hot = pd.get_dummies(df_train_NN['max_kerros'], prefix='max_kerros').astype('int')\n",
    "df_train_NN = pd.concat([df_train_NN, df_hot], axis=1)\n",
    "\n",
    "df_hot = pd.get_dummies(df_train_NN['Kunto'], prefix='Kunto').astype('int')\n",
    "df_train_NN = pd.concat([df_train_NN, df_hot], axis=1)\n",
    "\n",
    "df_hot = pd.get_dummies(df_train_NN['Hissi'], prefix='Hissi').astype('int')\n",
    "df_train_NN = pd.concat([df_train_NN, df_hot], axis=1)\n",
    "\n",
    "df_hot = pd.get_dummies(df_train_NN['Asunnon tyyppi'], prefix='Asunnon tyyppi').astype('int')\n",
    "df_train_NN = pd.concat([df_train_NN, df_hot], axis=1)\n",
    "\n",
    "df_hot = pd.get_dummies(df_train_NN[\"Talot.\"], prefix='Talot.').astype('int')\n",
    "df_train_NN = pd.concat([df_train_NN, df_hot], axis=1)\n",
    "\n",
    "\n",
    "df_train_NN.drop(['Kaupunginosa', 'kerros', 'max_kerros', 'Kunto', 'Hissi', 'Asunnon tyyppi', \"Talot.\"], axis=1, inplace=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Muodostetaan X ja y sekä jaetaan data harjoitus- ja testijoukkoihin\n",
    "\n",
    "X = df_train_NN.drop('Hinta', axis=1)\n",
    "y = df_train_NN['Hinta']\n",
    "\n",
    "X_train_NN, X_test_NN, y_train, y_test = train_test_split(X, y, test_size=0.1, stratify=df_train_NN['combined'], random_state=42)\n",
    "df_strat = X_train_NN['combined'].reset_index(drop=True)\n",
    "\n",
    "y_test.reset_index(drop=True, inplace=True)\n",
    "y_train.reset_index(drop=True, inplace=True)\n",
    "\n",
    "X_train_NN.drop('combined', axis=1, inplace=True)\n",
    "X_test_NN.drop('combined', axis=1, inplace=True)\n",
    "\n",
    "X_train_NN = X_train_NN.to_numpy().astype('float32')    \n",
    "X_test_NN = X_test_NN.to_numpy().astype('float32')\n",
    "\n",
    "y_train = y_train.to_numpy().astype('float32')\n",
    "y_test = y_test.to_numpy().astype('float32')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from keras import regularizers, layers, optimizers, initializers\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau, TerminateOnNaN\n",
    "import time \n",
    "from optuna.integration import TFKerasPruningCallback\n",
    "import os \n",
    "import pickle \n",
    "from datetime import timedelta\n",
    "\n",
    "# Kokeilaann paljonko tämä nopeuttaa NAS hakua\n",
    "# from tensorflow.keras import mixed_precision\n",
    "# mixed_precision.set_global_policy('mixed_float16')\n",
    "\n",
    "\n",
    "\n",
    "# Haun nimi\n",
    "study_name = '0329_rmsle_stratfold_layers'\n",
    "# Montako osittelua käytettiin\n",
    "folds = 5\n",
    "# Montako epochia kullekin osittelulle\n",
    "epochs_search = 50\n",
    "# Montako satunnaista hakua kieroksella\n",
    "num_random = 0\n",
    "# Montako TPE hakua kieroksella\n",
    "num_tpe = 50\n",
    "\n",
    "# Aika sekuntteina jota hakuun käytetän\n",
    "max_search_time = 40000\n",
    "# Neuroneiden maksimimäärä \n",
    "max_units_all = 128\n",
    "\n",
    "def rmsle_loss(y_true, y_pred):\n",
    "    penalty = tf.constant(1e5, dtype=tf.float32)\n",
    "    valid_mask = tf.math.greater(y_pred, 0.0)\n",
    "    safe_y_pred = tf.where(valid_mask, y_pred, penalty)\n",
    "    rmsle = tf.sqrt(tf.reduce_mean(tf.square(tf.math.log1p(safe_y_pred) - tf.math.log1p(y_true))))\n",
    "    return tf.where(tf.reduce_any(~valid_mask), penalty, rmsle)\n",
    "custom_objects = {\"rmsle_loss\": rmsle_loss}\n",
    "\n",
    "\n",
    "def create_model(trial):\n",
    "        \n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.layers.InputLayer(input_shape=(X_train_NN.shape[1],)))\n",
    "    \n",
    "    num_layers = trial.suggest_int('n_layers', 1, 3)\n",
    "    max_units = max_units_all\n",
    "\n",
    "    for i in range(num_layers):\n",
    "        # Ehdota neuronien määrää, joka on enintään max_units\n",
    "        num_units = trial.suggest_int(f'n_units_{i}', 4, max_units)\n",
    "        dropout_rate = trial.suggest_float(f'dropout_{i}', 0.0, 0.5)\n",
    "        kernel_regularizer = regularizers.l1_l2(\n",
    "            l1= trial.suggest_float(f'l1_reg_{i}', 1e-6, 1, log=True),\n",
    "            l2= trial.suggest_float(f'l2_reg_{i}', 1e-6, 1, log=True)\n",
    "        )\n",
    "        activation = trial.suggest_categorical(f'activation_{i}', ['relu', 'elu', 'LeakyReLU', 'tanh'])\n",
    "        \n",
    "        model.add(keras.layers.Dense(num_units, activation=activation, kernel_regularizer=kernel_regularizer))\n",
    "        model.add(keras.layers.Dropout(rate=dropout_rate))\n",
    "        \n",
    "        # Päivitä max_units varmistaaksesi, että seuraavan kerroksen neuronien määrä ei ole suurempi\n",
    "        max_units = min(max_units, num_units)  \n",
    "    \n",
    "    model.add(keras.layers.Dense(1, activation='linear')) \n",
    "    \n",
    "    # Optimisaattorin ja oppimisnopeuden valinta\n",
    "    optimizer_options = ['adam', 'rmsprop', 'Nadam', 'adamax', 'Adagrad', 'Adadelta']\n",
    "    optimizer_selected = trial.suggest_categorical('optimizer', optimizer_options)\n",
    "    \n",
    "    \n",
    "    if optimizer_selected == 'adam':\n",
    "        optimizer = optimizers.Adam()\n",
    "    elif optimizer_selected == 'rmsprop':\n",
    "        optimizer = optimizers.RMSprop()\n",
    "    elif optimizer_selected == 'Nadam':\n",
    "        optimizer = optimizers.Nadam()\n",
    "    elif optimizer_selected == 'Adagrad':\n",
    "        optimizer = optimizers.Adagrad()\n",
    "    elif optimizer_selected == 'Adadelta':\n",
    "        optimizer = optimizers.Adadelta()\n",
    "    else:\n",
    "        optimizer = optimizers.Adamax()\n",
    "\n",
    "    model.compile(optimizer=optimizer, loss=rmsle_loss, metrics=['mse', 'mae'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "def objective(trial):\n",
    "\n",
    "    model = create_model(trial)\n",
    "    batch_size = trial.suggest_int('batch_size', 16, 128, log=True)    \n",
    "    callbacks = [TFKerasPruningCallback(trial, 'val_loss'),\n",
    "                 ReduceLROnPlateau('val_loss', patience=5, factor=0.5), \n",
    "                 TerminateOnNaN()]\n",
    "\n",
    "    history = model.fit(X_train_b, y_train_b, epochs=epochs_search, validation_data=(X_val_b, y_val_b) ,batch_size=batch_size, verbose=0, callbacks=callbacks)\n",
    "    val_loss = np.min(history.history['val_loss'])\n",
    "    \n",
    "    return val_loss\n",
    "\n",
    "\n",
    "####\n",
    "\n",
    "total_time_start = time.time()  \n",
    "search_time_start = time.time() \n",
    "num_completed_trials = 0\n",
    "search_rounds = 0\n",
    "time_taken = 0\n",
    "\n",
    "while time_taken < max_search_time:\n",
    "        \n",
    "    fold = 0 \n",
    "    time_fold_start = time.time()    \n",
    "    skf =  StratifiedKFold(n_splits=folds, shuffle=True, random_state=42)\n",
    "\n",
    "    stratified_labels = df_strat\n",
    "    \n",
    "    for train_index, val_index in skf.split(X_train_NN, stratified_labels):\n",
    "\n",
    "        print('-------------------')\n",
    "        print(f\"Starting fold {fold} search...\")\n",
    "        X_train_b, X_val_b = X_train_NN[train_index], X_train_NN[val_index]    \n",
    "        y_train_b, y_val_b = y_train[train_index], y_train[val_index]\n",
    "\n",
    "        fold_name = f'{study_name}_{fold}'\n",
    "       \n",
    "        study = optuna.create_study(direction='minimize',\n",
    "                                    pruner=optuna.pruners.HyperbandPruner(min_resource=10),\n",
    "                                    study_name=fold_name,\n",
    "                                    storage=f'sqlite:///tampere_reg.db',\n",
    "                                    load_if_exists=True                                 \n",
    "                                    )\n",
    "        \n",
    "    \n",
    "        fold_time = time.time()    \n",
    "\n",
    "        fold_random = time.time()\n",
    "        optuna.logging.set_verbosity(optuna.logging.WARNING)     \n",
    "\n",
    "        if num_random > 0:   \n",
    "            study.sampler = optuna.samplers.QMCSampler(warn_independent_sampling = False) # TODO tämä testiin, vaikutti paljon paremmalta kuin random \n",
    "            print(f'Random search for fold {fold}...')\n",
    "            study.optimize(objective, n_trials=num_random)\n",
    "            print(f'Time taken for random search: {str(timedelta(seconds=(time.time() - fold_random)))}')\n",
    "\n",
    "        fold_tpe = time.time()  \n",
    "        if num_tpe > 0:\n",
    "            study.sampler = optuna.samplers.TPESampler(n_startup_trials=0)\n",
    "            print(f'TPE search for fold {fold}...')\n",
    "            study.optimize(objective, n_trials=num_tpe)\n",
    "            print(f'Time taken for TPE search: {str(timedelta(seconds=(time.time() - fold_tpe)))}')\n",
    "\n",
    "        num_completed_trials += num_random + num_tpe\n",
    "        print('-------------------')\n",
    "        print(f'Finished fold {fold} search.')\n",
    "        print(f\"Time taken for this fold: {str(timedelta(seconds=(time.time() - fold_time)))}\")                \n",
    "        print(f'Fold {fold} best value so far: {study.best_value}')\n",
    "        print(f'Best parameters so far: {study.best_params}')\n",
    "        print(f'Mean time for one trial this fold: {str(timedelta(seconds=(time.time() - fold_time) / (num_random + num_tpe)))}')\n",
    "        print(f'This fold has made total {study.trials_dataframe().shape[0]} trials.')\n",
    "\n",
    "        fold += 1\n",
    "    search_rounds += 1\n",
    "    \n",
    "    time_taken = time.time() - search_time_start\n",
    "    \n",
    "    print(f'\\n# Completed search round: {search_rounds} #')\n",
    "    print(f'Time taken for all folds this round: {str(timedelta(seconds=(time.time() - time_fold_start)))}')\n",
    "    print(f'Total time taken for search: {str(timedelta(seconds=(time.time() - search_time_start)))}')\n",
    "    print(f'Made trials this far: {num_completed_trials}')\n",
    "    print(f\"Current mean time for one trial: {str(timedelta(seconds=(time.time() - search_time_start) / num_completed_trials))}\\n\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import timedelta\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "import optuna\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from keras import regularizers, layers, optimizers, initializers\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau, TerminateOnNaN\n",
    "import time \n",
    "import os \n",
    "\n",
    "def rmsle_score(y_true, y_pred):\n",
    "    return np.sqrt(mean_squared_error(np.log1p(y_true+1), np.log1p(y_pred+1)))\n",
    "\n",
    "folds = 5\n",
    "# Montako epochia kullekin parhaalle sovitetaan malli\n",
    "epochs_best_fit = 500\n",
    "# Montako paras otetaan mukaan osittelusta\n",
    "num_best = 4\n",
    "# Montako kertaa kullekin parhaalle sovitetaan malli\n",
    "num_best_fits = 1\n",
    "\n",
    "best_optuna_models = []\n",
    "best_val_scores = []\n",
    "best_optuna_trials = [] \n",
    "fitting_search_start = time.time()\n",
    "\n",
    "\n",
    "\n",
    "skf =  StratifiedKFold(n_splits=folds, shuffle=True, random_state=42)\n",
    "stratified_labels = df_strat\n",
    "fold_num = 0    \n",
    "for train_index, val_index in skf.split(X_train_NN, stratified_labels):\n",
    "\n",
    "    best_fitting_time = time.time()\n",
    "    print(f\"Fold {fold_num} Best best trial fitting...\")\n",
    "\n",
    "    X_train_b, X_val_b = X_train_NN[train_index], X_train_NN[val_index]    \n",
    "    y_train_b, y_val_b = y_train[train_index], y_train[val_index]\n",
    "    \n",
    "    fold_name = f'{study_name}_{fold_num}'\n",
    "       \n",
    "    study = optuna.create_study(                                \n",
    "                                study_name=fold_name,\n",
    "                                storage=f'sqlite:///tampere_reg.db',\n",
    "                                load_if_exists=True\n",
    "                                )\n",
    "\n",
    "    valid_trials = [trial for trial in study.trials if trial.value is not None]\n",
    "    sorted_trials = sorted(valid_trials, key=lambda trial: trial.value)\n",
    "    best_trials = sorted_trials[:num_best]\n",
    "    best_val = np.inf\n",
    "    best_model = None\n",
    "\n",
    "    print('='*30)\n",
    "    print(f'Fitting best trials for fold {fold_num}...')\n",
    "    fitting_fold_best_start = time.time()\n",
    "    \n",
    "    for trial in best_trials:\n",
    "\n",
    "        for fit_num in range(num_best_fits):\n",
    "            \n",
    "            print('-'*30)\n",
    "            print(f\"Trial ID: {trial.number}, Value: {trial.value}, fit number: {fit_num}\")\n",
    "\n",
    "            checkpoint_filepath = f'./NN_search/optuna_search_checkpoint.h5'\n",
    "            model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "                filepath=checkpoint_filepath,\n",
    "                save_weights_only=True,\n",
    "                monitor='val_loss',\n",
    "                mode='min',\n",
    "                save_best_only=True)\n",
    "\n",
    "            best_callback = [model_checkpoint_callback,                  \n",
    "                            ReduceLROnPlateau('val_loss', patience=10, factor=0.8), \n",
    "                            TerminateOnNaN(),\n",
    "                            EarlyStopping(monitor='val_loss', patience=100, verbose=1)\n",
    "                        ]\n",
    "\n",
    "\n",
    "            model = create_model(trial)\n",
    "            model.fit(X_train_b, y_train_b, epochs=epochs_best_fit, validation_data=(X_val_b, y_val_b), batch_size=trial.params['batch_size'], verbose=0, callbacks=best_callback)\n",
    "            model.load_weights(checkpoint_filepath)\n",
    "\n",
    "            predictions = model.predict(X_val_b, verbose=0)\n",
    "            mse = mean_squared_error(y_val_b, predictions)\n",
    "            mae = mean_absolute_error(y_val_b, predictions)\n",
    "            r2 = r2_score(y_val_b, predictions)\n",
    "            rmsle = rmsle_score(y_val_b, predictions)\n",
    "\n",
    "                        \n",
    "            print(f'MSE:{mse:.5f}\\nMAE:{mae:.5f}\\nRMSLE:{rmsle:.5f}\\nR2:{r2:.5f}')\n",
    "\n",
    "            if rmsle < best_val:\n",
    "                best_model = model\n",
    "                best_val = rmsle\n",
    "                best_trial_num = trial.number\n",
    "                best_trial = trial\n",
    "                print(f'*** New best model for fold {fold_num} is Trial {best_trial_num} with RMSLE {best_val} ***')\n",
    "                print(f'Best trial hyperparameters: {trial.params}')\n",
    "    \n",
    "    if best_model is not None:\n",
    "        \n",
    "        best_optuna_models.append(best_model)\n",
    "        best_val_scores.append(best_val)\n",
    "        best_optuna_trials.append(best_trial)\n",
    "        print('*'*40)\n",
    "        print(f\"Best model for fold {fold_num} RMSLE: {best_val}\\nTrial number: {best_trial_num}\\nHyperparameters: {best_trial.params}\")\n",
    "        print('*'*40)\n",
    "\n",
    "    print(f\"Time taken for best fitting in fold {fold_num}: {str(timedelta(seconds=(time.time() - best_fitting_time)) )}\")\n",
    "\n",
    "    fold_num += 1\n",
    "\n",
    "print('*'*40)\n",
    "print(f'Best models fitting time total:', str(timedelta(seconds=(time.time() - fitting_search_start))))\n",
    "print(f\"Total time taken for search and fitting best models: {str(timedelta(seconds=(time.time() - total_time_start)))}\")\n",
    "print('*'*40)   \n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "for i, (model, score) in enumerate(zip(best_optuna_models, best_val_scores)):\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    directory = f\"./NN_search/{study_name}_foldmodel{i}_score_{score:.4f}_{timestamp}.h5\"\n",
    "    print(f\"Saving model {i} with score {score:.4f} to {directory}\")\n",
    "    model.save(directory)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "from sklearn.model_selection import KFold\n",
    "import time\n",
    "\n",
    "# Oletetaan, että rmsle_score ja create_model funktiot ovat määritelty\n",
    "\n",
    "folds = 5\n",
    "epochs_best_fit = 500\n",
    "\n",
    "# Ladataan kaikki studyt ja etsitään globaalisti paras trial\n",
    "best_global_val = float('inf')\n",
    "best_global_trial = None\n",
    "best_optuna_models_global = []\n",
    "\n",
    "for fold_num in range(folds):\n",
    "    \n",
    "     \n",
    "    fold_name = f'{study_name}_{fold_num}'    \n",
    "    study = optuna.create_study(                                \n",
    "                                study_name=fold_name,\n",
    "                                storage=f'sqlite:///tampere_reg.db',\n",
    "                                load_if_exists=True\n",
    "                                )\n",
    "    valid_trials = [trial for trial in study.trials if trial.value is not None]\n",
    "    sorted_trials = sorted(valid_trials, key=lambda trial: trial.value)\n",
    "    best_trial = sorted_trials[0].value\n",
    "\n",
    "    if best_trial < best_global_val:\n",
    "        best_global_val = best_trial\n",
    "        best_global_trial = sorted_trials[0]\n",
    "        best_fold = fold_num\n",
    "        print(f'New best global trial value: {best_global_val:.4f} found in fold {best_fold}')\n",
    "        \n",
    "print(f'Best global trial value: {best_global_val:.4f} tahat found in fold {best_fold}')\n",
    "\n",
    "# Nyt meillä on paras trial, jota käytetään kaikkien foldien kouluttamiseen\n",
    "\n",
    "skf =  StratifiedKFold(n_splits=folds, shuffle=True, random_state=42)\n",
    "stratified_labels = df_strat\n",
    "\n",
    "fold_num = 0\n",
    "for train_index, val_index in skf.split(X_train_NN, stratified_labels):\n",
    "    print(f\"Training fold {fold_num} using best global trial...\")\n",
    "    \n",
    "    X_train_b, X_val_b = X_train_NN[train_index], X_train_NN[val_index]\n",
    "    y_train_b, y_val_b = y_train[train_index], y_train[val_index]\n",
    "\n",
    "    # Luodaan malli parhaan trialin parametreilla\n",
    "    model = create_model(best_global_trial)\n",
    "\n",
    "    checkpoint_filepath = f'./NN_search/optuna_search_checkpoint.h5'\n",
    "    model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath=checkpoint_filepath,\n",
    "        save_weights_only=True,\n",
    "        monitor='val_loss',\n",
    "        mode='min',\n",
    "        save_best_only=True)\n",
    "\n",
    "\n",
    "    best_callback = [model_checkpoint_callback,                  \n",
    "                        ReduceLROnPlateau('val_loss', patience=10, factor=0.8), \n",
    "                        TerminateOnNaN(),\n",
    "                        EarlyStopping(monitor='val_loss', patience=100, verbose=1)\n",
    "                    ]\n",
    "    \n",
    "    # Koulutetaan malli\n",
    "    model.fit(X_train_b, y_train_b, epochs=epochs_best_fit, validation_data=(X_val_b, y_val_b), batch_size=best_global_trial.params['batch_size'], verbose=0, callbacks=best_callback)\n",
    "    model.load_weights(checkpoint_filepath)\n",
    "    \n",
    "    # Tarkistetaan mallin suorituskykyä (tämä osa voi vaatia mukauttamista projektisi tarpeisiin)\n",
    "    predictions = model.predict(X_val_b)\n",
    "    rmsle = rmsle_score(y_val_b, predictions)\n",
    "    print(f\"Fold {fold_num} RMSLE: {rmsle}\")\n",
    "\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    directory = f\"./NN_search/{study_name}_best_foldmodel{fold_num}_score_{rmsle:.4f}_{timestamp}.h5\"\n",
    "    print(f\"Saving model {fold_num} with score {rmsle:.4f} to {directory}\")\n",
    "    model.save(directory)\n",
    "    best_optuna_models_global.append(model)\n",
    "    fold_num += 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, model in enumerate(best_optuna_models_global):\n",
    "    print(f\"\\nModel {idx} Summary:\")\n",
    "    # model.summary()\n",
    "    \n",
    "    # Testaa mallia testidatalla\n",
    "    predictions = model.predict(X_test_NN, verbose = 0)\n",
    "    mse = mean_squared_error(y_test, predictions)\n",
    "    mae = mean_absolute_error(y_test, predictions)\n",
    "    r2 = r2_score(y_test, predictions)\n",
    "    rmsle = rmsle_score(y_test, predictions)\n",
    "    \n",
    "    print(f\"\\nModel {idx} Performance on Test Data:\")\n",
    "    print(f\"MSE: {mse:.3f}\")\n",
    "    print(f\"MAE: {mae:.3f}\")\n",
    "    print(f\"R2: {r2:.3f}\")\n",
    "    print(f\"RMSLE: {rmsle:.3f}\")\n",
    "    print(\"*\"*40)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Models with best fold trial fitted')\n",
    "for idx, model in enumerate(best_optuna_models):\n",
    "    print(f\"\\nModel {idx} Summary:\")\n",
    "    # model.summary()\n",
    "    \n",
    "    # Testaa mallia testidatalla\n",
    "    predictions = model.predict(X_test_NN, verbose = 0)\n",
    "    mse = mean_squared_error(y_test, predictions)\n",
    "    mae = mean_absolute_error(y_test, predictions)\n",
    "    r2 = r2_score(y_test, predictions)\n",
    "    rmsle = rmsle_score(y_test, predictions)\n",
    "    \n",
    "    print(f\"\\nModel {idx} Performance on Test Data:\")\n",
    "    print(f\"MSE: {mse:.3f}\")\n",
    "    print(f\"MAE: {mae:.3f}\")\n",
    "    print(f\"R2: {r2:.3f}\")\n",
    "    print(f\"RMSLE: {rmsle:.3f}\")\n",
    "    print(\"*\"*40)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import timedelta\n",
    "import time\n",
    "from tensorflow.keras.models import Model\n",
    "import glob\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.feature_selection import SelectKBest, f_regression, mutual_info_regression\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "import warnings\n",
    "\n",
    "# Estä kaikki UserWarning-varoitukset näkymästä\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "\n",
    "# study_name = '0329_rmsle5_layers'\n",
    "# study_name = 'rmsle5_random_2503'\n",
    "\n",
    "study_name = '0329_rmsle_stratfold_layers'\n",
    "\n",
    "num_random = 4000\n",
    "num_tpe = 200\n",
    "\n",
    "time_started_xgb = time.time()\n",
    "\n",
    "def rmsle_loss(y_true, y_pred):\n",
    "    penalty = tf.constant(1e5, dtype=tf.float32)\n",
    "    valid_mask = tf.math.greater(y_pred, 0.0)\n",
    "    safe_y_pred = tf.where(valid_mask, y_pred, penalty)\n",
    "    rmsle = tf.sqrt(tf.reduce_mean(tf.square(tf.math.log1p(safe_y_pred) - tf.math.log1p(y_true))))\n",
    "    return tf.where(tf.reduce_any(~valid_mask), penalty, rmsle)\n",
    "custom_objects = {\"rmsle_loss\": rmsle_loss}\n",
    "\n",
    "model_best_vals = []\n",
    "best_optuna_models = []\n",
    "\n",
    "folds = 5\n",
    "\n",
    "for fold_num in range(folds): # TODO testiä parhailla malleilla\n",
    "    patterns = [\n",
    "        f\"./NN_search/{study_name}_best_foldmodel{fold_num}_score_*.h5\",\n",
    "        f\"./NN_search/{study_name}_foldmodel{fold_num}_score_*.h5\"\n",
    "    ]\n",
    "    \n",
    "    best_score = float('inf')\n",
    "    best_model_file = None\n",
    "    for pattern in patterns:\n",
    "        model_files = glob.glob(pattern)\n",
    "        for model_file in model_files:\n",
    "            score_part = model_file.split('_score_')[1]\n",
    "            score = float(score_part.split('_')[0])\n",
    "            if score < best_score:\n",
    "                best_score = score\n",
    "                best_model_file = model_file\n",
    "                    \n",
    "    model_best_vals.append(best_score)    \n",
    "    # Lataa parhaan mallin tiedosto\n",
    "    if best_model_file:\n",
    "        best_model = load_model(best_model_file, custom_objects=custom_objects)\n",
    "        best_optuna_models.append(best_model)\n",
    "        print(f\"Loaded best model for fold {fold_num} from {best_model_file} with score {best_score:.4f}\")\n",
    "    else:\n",
    "        print(f\"No model files found for fold {fold_num} matching pattern {pattern}\")\n",
    "\n",
    "\n",
    "\n",
    "X_train_features_list = []\n",
    "X_test_features_list = []\n",
    "features_names_list = []\n",
    "\n",
    "for idx, model in enumerate(best_optuna_models):\n",
    "    feature_extractor = Model(inputs=model.inputs, outputs=model.layers[-2].output)\n",
    "    X_train_features = feature_extractor.predict(X_train_NN)\n",
    "    X_test_features = feature_extractor.predict(X_test_NN)\n",
    "    \n",
    "    X_train_features_list.append(X_train_features)\n",
    "    X_test_features_list.append(X_test_features)\n",
    "\n",
    "    print(f'Model train feature shape: {X_train_features.shape}')\n",
    "    print(f'Model test feature shape: {X_test_features.shape}')\n",
    "\n",
    "    num_features = X_train_features.shape[1]\n",
    "    model_feature_names = [f\"model_{idx}_feature_{feature_idx}\" for feature_idx in range(num_features)]\n",
    "    features_names_list.append(model_feature_names)\n",
    "\n",
    "\n",
    "original_feature_names = list(X_train.columns) \n",
    "# combined_feature_names = original_feature_names + features_names_list\n",
    "\n",
    "# print(f'Train combined feature shape: {X_train_features.shape}')\n",
    "# print(f'Test combined feature shape: {X_test_features.shape}')\n",
    "\n",
    "# Yhdistetään ominaisuusvektorit\n",
    "\n",
    "def select_models(X_train_features_list, X_test_features_list, features_names_list, which_models):\n",
    "\n",
    "    X_train_selected = []\n",
    "    X_test_selected = []\n",
    "    selected_names = []\n",
    "\n",
    "    if all(not choosenode for choosenode in which_models):        \n",
    "        X_train_selected = None\n",
    "        X_test_selected = None\n",
    "        selected_names = None\n",
    "\n",
    "    else:\n",
    "        for idx, choosenode in enumerate(which_models):\n",
    "            if choosenode: \n",
    "                X_train_selected.append(X_train_features_list[idx])\n",
    "                X_test_selected.append(X_test_features_list[idx])\n",
    "                selected_names.extend(features_names_list[idx])                \n",
    "            \n",
    "        X_train_selected = np.concatenate(X_train_selected, axis=1)\n",
    "        X_test_selected = np.concatenate(X_test_selected, axis=1)\n",
    "        \n",
    "        \n",
    "    return X_train_selected, X_test_selected, selected_names\n",
    "    \n",
    "\n",
    "# X_train_combined = np.concatenate(X_train_features_list, axis=1)\n",
    "# X_test_combined = np.concatenate(X_test_features_list, axis=1)\n",
    "\n",
    "# X_train_combined = np.concatenate([X_train_combined, X_train], axis=1)   \n",
    "# X_test_combined = np.concatenate([X_test_combined, X_test], axis=1)\n",
    "\n",
    "def select_features(X_train_combined, X_test_combined, y_train, combined_feature_names, method, max_feature):\n",
    "    \n",
    "    if method == 'f_regression':\n",
    "        method_function = f_regression\n",
    "    elif method == 'mutual_info_regression':\n",
    "        method_function = mutual_info_regression\n",
    "    else:\n",
    "        method_function = None\n",
    "\n",
    "    if method_function is not None:\n",
    "        selector = SelectKBest(method_function, k=max_feature)\n",
    "        X_train_combined_selected = selector.fit_transform(X_train_combined, y_train)\n",
    "        X_test_combined_selected = selector.transform(X_test_combined)\n",
    "        selected_indices = selector.get_support(indices=True)\n",
    "        selected_features_names = np.array(combined_feature_names)[selected_indices]\n",
    "        selected_features_names = selected_features_names.tolist()\n",
    "        \n",
    "        return X_train_combined_selected, X_test_combined_selected, selected_features_names\n",
    "    else:\n",
    "        return X_train_combined, X_test_combined, combined_feature_names\n",
    "\n",
    "\n",
    "def rmsle(y_true, y_pred):\n",
    "    if np.any(y_pred <= 0):\n",
    "        return 1e6\n",
    "    return np.sqrt(np.mean(np.square(np.log1p(y_pred) - np.log1p(y_true))))\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "    # Määritetään parametrit, jotka optimoidaan\n",
    "    param = {\n",
    "        \"booster\": \"dart\",\n",
    "        # \"booster\": trial.suggest_categorical(\"booster\", [\"gbtree\", \"dart\"]),\n",
    "        'max_depth': trial.suggest_int('max_depth', 1, 6),\n",
    "        \"lambda\": trial.suggest_float(\"lambda\", 1e-4, 1.0, log=True),\n",
    "        \"alpha\": trial.suggest_float(\"alpha\", 1e-4, 1.0, log=True),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 1e-2, 2, log=True),\n",
    "        'subsample': trial.suggest_float('subsample', 0.2, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.2, 1.0),\n",
    "        'gamma': trial.suggest_float('gamma', 0.1, 42, log = True)     \n",
    "        # 'nthread' : -3 \n",
    "    }\n",
    "\n",
    "    num_boost_round = trial.suggest_int('BRounds', 1, 142)  \n",
    "    selector = trial.suggest_categorical('S', choices = ['f_regression', 'mutual_info_regression', 'None'])\n",
    "\n",
    "    select_0 = trial.suggest_categorical('S0', [True, False])\n",
    "    select_1 = trial.suggest_categorical('S1', [True, False])\n",
    "    select_2 = trial.suggest_categorical('S2', [True, False])\n",
    "    select_3 = trial.suggest_categorical('S3', [True, False])\n",
    "    select_4 = trial.suggest_categorical('S4', [True, False])\n",
    "\n",
    "    X_train_combined_selected, X_test_combined_selected , selected_features_names = select_models(X_train_features_list, X_test_features_list, features_names_list, [select_0, select_1, select_2, select_3, select_4])\n",
    "\n",
    "    if X_train_combined_selected is not None:\n",
    "        combined_feature_names = selected_features_names + original_feature_names\n",
    "        X_train_combined_selected = np.concatenate([X_train_combined_selected, X_train], axis=1)\n",
    "        X_test_combined_selected = np.concatenate([X_test_combined_selected, X_test], axis=1)\n",
    "    else:\n",
    "        X_train_combined_selected = X_train\n",
    "        X_test_combined_selected = X_test\n",
    "        combined_feature_names = original_feature_names\n",
    "\n",
    "\n",
    "    num_selected = trial.suggest_int('N_fea', 1, X_train_combined_selected.shape[1])\n",
    "    X_train_combined_selected, _ , combined_feature_names = select_features(X_train_combined_selected, X_test_combined_selected, y_train, combined_feature_names, selector, num_selected)\n",
    "    # print(f\"Selected features: {combined_feature_names}\")\n",
    "    \n",
    "    \n",
    "    rmsle_scores = []\n",
    "    dtrain_full = xgb.DMatrix(X_train_combined_selected, label=y_train, feature_names=combined_feature_names)\n",
    "\n",
    "    skf =  StratifiedKFold(n_splits=folds, shuffle=True, random_state=42)\n",
    "    stratified_labels = df_strat\n",
    "    for train_index, val_index in skf.split(X_train_NN, stratified_labels):\n",
    "        \n",
    "        dtrain = dtrain_full.slice(train_index)\n",
    "        dval = dtrain_full.slice(val_index)\n",
    "\n",
    "        evals_result = {}\n",
    "        bst = xgb.train(param, dtrain, num_boost_round=num_boost_round, evals=[(dval, 'val')], evals_result=evals_result, verbose_eval=False, early_stopping_rounds=1000)\n",
    "        best_iteration = bst.best_iteration\n",
    "        preds = bst.predict(dval, iteration_range=(0, best_iteration + 1))\n",
    "        y_true = y_train[val_index]\n",
    "        # loss = r2_score(y_true, preds)\n",
    "        loss = rmsle(y_true, preds)\n",
    "        rmsle_scores.append(loss)\n",
    "\n",
    "    average_rmsle = np.mean(rmsle_scores)\n",
    "    return average_rmsle\n",
    "\n",
    "# study = optuna.create_study(direction='maximize', \n",
    "#                             storage='sqlite:///tampere_reg.db', \n",
    "#                             study_name='0326_xgb_comb_R2', # TODO muuta nimeä tarvittaessa\n",
    "#                             load_if_exists=False) \n",
    "\n",
    "study = optuna.create_study(direction='minimize')\n",
    "\n",
    "# optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "optuna.logging.set_verbosity(optuna.logging.INFO)\n",
    "study.sampler = optuna.samplers.QMCSampler(warn_independent_sampling = False)\n",
    "print(f'Random sampling {num_random} trials...')\n",
    "study.optimize(objective, n_trials=num_random)\n",
    "study.sampler = optuna.samplers.TPESampler()\n",
    "print(f'TPE sampling {num_tpe} trials...')\n",
    "study.optimize(objective, n_trials=num_tpe)\n",
    "\n",
    "print(f'Time taken for XGBoost optimization: {str(timedelta(seconds=(time.time() - time_started_xgb)))}')\n",
    "print(f'Time taken for one trial: {str(timedelta(seconds=(time.time() - time_started_xgb) / (num_random + num_tpe)))}')\n",
    "\n",
    "# Parhaiden parametrien tulostus ja mallin koulutus\n",
    "print(f\"Best val: {study.best_trial.value}\")\n",
    "print(f'Best params: {study.best_params}')\n",
    "\n",
    "# X_train_combined_selected, X_test_combined_selected, selected_features_names = select_features(X_train_combined, X_test_combined, y_train, combined_feature_names, study.best_params['selector'], study.best_params['num_selected_features'])\n",
    "\n",
    "X_train_combined_selected, X_test_combined_selected , selected_features_names = select_models(X_train_features_list, X_test_features_list, features_names_list, [study.best_params['S0'], study.best_params['S1'], study.best_params['S2'], study.best_params['S3'], study.best_params['S4']])\n",
    "\n",
    "if X_train_combined_selected is not None:\n",
    "    combined_feature_names = selected_features_names + original_feature_names\n",
    "    X_train_combined_selected = np.concatenate([X_train_combined_selected, X_train], axis=1)\n",
    "    X_test_combined_selected = np.concatenate([X_test_combined_selected, X_test], axis=1)\n",
    "else:\n",
    "    X_train_combined_selected = X_train\n",
    "    X_test_combined_selected = X_test\n",
    "    combined_feature_names = original_feature_names\n",
    "\n",
    "X_train_combined_selected, X_test_combined_selected, selected_features_names = select_features(X_train_combined_selected, X_test_combined_selected, y_train, combined_feature_names, study.best_params['S'], study.best_params['N_fea'])\n",
    "\n",
    "dtrain = xgb.DMatrix(X_train_combined_selected, label=y_train, feature_names=selected_features_names)\n",
    "best_model = xgb.train(study.best_params, dtrain, num_boost_round=study.best_params['BRounds'])\n",
    "\n",
    "# Testataan mallia koulutusdatalla jotta voidaan arvioida overfittingia\n",
    "pred_train = best_model.predict(dtrain)\n",
    "mae_train = mean_absolute_error(y_train, pred_train)\n",
    "mse_train = mean_squared_error(y_train, pred_train)\n",
    "r2_train = r2_score(y_train, pred_train)\n",
    "rmsle_train = rmsle(y_train, pred_train)\n",
    "print(f\"Train MAE: {mae_train}, Train MSE: {mse_train}, Train R2: {r2_train}, Train RMSLE: {rmsle_train}\")\n",
    "\n",
    "dtest = xgb.DMatrix(X_test_combined_selected, label=y_test, feature_names=selected_features_names)\n",
    "predictions = best_model.predict(dtest)\n",
    "\n",
    "mse = mean_squared_error(y_test, predictions)\n",
    "mae = mean_absolute_error(y_test, predictions)\n",
    "r2 = r2_score(y_test, predictions)\n",
    "rmsle_val = rmsle(y_test, predictions)\n",
    "print(f\"MAE: {mae}, MSE: {mse}, R2: {r2}, RMSLE: {rmsle_val}\")\n",
    "\n",
    "# Visualisoidaan ennustettuja arvoja verrattuna todellisiin arvoihin\n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.scatter(y_test, predictions, edgecolors=(0, 0, 0))\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--', lw=4)\n",
    "plt.xlabel('Measured')\n",
    "plt.ylabel('Predicted')\n",
    "plt.title('Measured vs. Predicted Values')\n",
    "plt.show()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20, 30))\n",
    "xgb.plot_importance(best_model, importance_type='weight', ax=ax)\n",
    "ax.set_title('Feature Importance by Weight', fontsize=16)\n",
    "plt.show()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20, 30))\n",
    "xgb.plot_importance(best_model, importance_type='gain', ax=ax)\n",
    "ax.set_title('Feature Importance by Gain', fontsize=16)\n",
    "plt.show()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20, 30))\n",
    "xgb.plot_importance(best_model, importance_type='cover', ax=ax)\n",
    "ax.set_title('Feature Importance by Cover', fontsize=16)\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "### Testataan vielä minkälaisia tuloksia vain NN mallien ennustuksilla ### \n",
    "\n",
    "predictions_train = []\n",
    "\n",
    "for idx, model in enumerate(best_optuna_models):\n",
    "    pred = model.predict(X_train_NN, verbose=0).flatten()\n",
    "    predictions_train.append(pred)\n",
    "\n",
    "predictions_test = []\n",
    "\n",
    "for idx, model in enumerate(best_optuna_models):\n",
    "    pred = model.predict(X_test_NN, verbose=0).flatten()\n",
    "    predictions_test.append(pred)\n",
    "\n",
    "### Keskiarvo \n",
    "print('Keskiarvo ')\n",
    "predictions_mean = np.mean(predictions_test, axis=0)\n",
    "mse = mean_squared_error(y_test, predictions_mean)\n",
    "mae = mean_absolute_error(y_test, predictions_mean)\n",
    "r2 = r2_score(y_test, predictions_mean)\n",
    "rmsle_val = rmsle(y_test, predictions_mean)  \n",
    "print(f\"MAE: {mae}, MSE: {mse}, R2: {r2}, RMSLE: {rmsle_val}\\n\\n\")\n",
    "\n",
    "### Painotettu keskiarvo\n",
    "print('Painotettu keskiarvo käänteisillä')\n",
    "best_rmsle = float('inf')\n",
    "for pot in range (1,20):\n",
    "    weights = [1 / x**pot for x in model_best_vals]\n",
    "    w_sum = sum(weights)\n",
    "    weights = [x / w_sum for x in weights]\n",
    "    weighted_predictions = np.average(predictions_test, axis=0, weights=weights)\n",
    "    mse = mean_squared_error(y_test, weighted_predictions)\n",
    "    mae = mean_absolute_error(y_test, weighted_predictions)\n",
    "    r2 = r2_score(y_test, weighted_predictions)\n",
    "    rmsle_val = rmsle(y_test, weighted_predictions)  # Oletetaan että sinulla on rmsle funktio määritelty\n",
    "    if rmsle_val < best_rmsle:\n",
    "        best_rmsle = rmsle_val\n",
    "        bestpot = pot\n",
    "print(f'Paras arvo löytyi potenssilla {bestpot} arvolla {best_rmsle}')\n",
    "        \n",
    "\n",
    "### Lineaarinen regressio \n",
    "from sklearn.linear_model import LinearRegression\n",
    "# Oletetaan, että `predictions` on lista, joka sisältää kunkin mallin ennusteet testidatasetille\n",
    "X_meta_train = np.stack(predictions_train, axis=1)\n",
    "X_meta_test = np.stack(predictions_test, axis=1)\n",
    "# Koulutetaan meta-malli\n",
    "meta_model = LinearRegression()\n",
    "meta_model.fit(X_meta_train, y_train)\n",
    "\n",
    "# Käytetään meta-mallia ennustamaan\n",
    "linear_predictions = meta_model.predict(X_meta_test)\n",
    "\n",
    "print('Linear meta')\n",
    "mse = mean_squared_error(y_test, linear_predictions)\n",
    "mae = mean_absolute_error(y_test, linear_predictions)\n",
    "r2 = r2_score(y_test, linear_predictions)\n",
    "rmsle_val = rmsle(y_test, linear_predictions)  # Oletetaan että sinulla on rmsle funktio määritelty\n",
    "print(f\"MAE: {mae}, MSE: {mse}, R2: {r2}, RMSLE: {rmsle_val}\\n\\n\")\n",
    "\n",
    "### XGBoost \n",
    "import optuna\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "time_xgb = time.time()\n",
    "\n",
    "NN_names = [f'NN_{i}' for i in range(len(best_optuna_models))]\n",
    "\n",
    "X_train_XGB = np.column_stack(predictions_train)\n",
    "X_test_XGB = np.column_stack(predictions_test)\n",
    "\n",
    "def objective(trial):\n",
    "    # XGBoostin parametrit, jotka optimoidaan\n",
    "    param = {        \n",
    "        'objective': 'reg:absoluteerror',      \n",
    "        \"booster\": trial.suggest_categorical(\"booster\", [\"gbtree\", \"dart\"]),\n",
    "        \"lambda\": trial.suggest_float(\"lambda\", 1e-6, 1.0, log = True),\n",
    "        \"alpha\": trial.suggest_float(\"alpha\", 1e-6, 1.0, log = True),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 1, 6),\n",
    "        \"learning_rate\": trial.suggest_float(\"eta\", 1e-2, 1.0),\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.2, 1.0),\n",
    "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.2, 1.0),\n",
    "        'gamma': trial.suggest_float('gamma', 0, 10)\n",
    "    }\n",
    "\n",
    "    num_boost_round = trial.suggest_int('num_boost_round', 1, 142)  \n",
    "\n",
    "    kf = KFold(n_splits=5)\n",
    "    rmsle_scores = []\n",
    "\n",
    "    dtrain_full = xgb.DMatrix(X_train_XGB, label=y_train, feature_names=NN_names)\n",
    "\n",
    "    for train_index, val_index in kf.split(X_train_XGB):\n",
    "        dtrain = dtrain_full.slice(train_index)\n",
    "        dval = dtrain_full.slice(val_index)\n",
    "\n",
    "        evals_result = {}\n",
    "        bst = xgb.train(param, dtrain, num_boost_round=num_boost_round, evals=[(dval, 'val')], evals_result=evals_result, verbose_eval=False, early_stopping_rounds=200)\n",
    "        \n",
    "        best_iteration = bst.best_iteration\n",
    "        preds = bst.predict(dval, iteration_range=(0, best_iteration + 1))\n",
    "        y_true = y_train[val_index]\n",
    "        loss = r2_score(y_true, preds)\n",
    "        # loss = rmsle(y_true, preds)\n",
    "        rmsle_scores.append(loss)\n",
    "        \n",
    "    return np.mean(rmsle_scores)\n",
    "\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.sampler = optuna.samplers.QMCSampler(warn_independent_sampling = False)\n",
    "study.optimize(objective, n_trials=42)\n",
    "print(f'Random sampling trials...')\n",
    "study.sampler = optuna.samplers.TPESampler()\n",
    "print(f'TPE sampling trials...')\n",
    "study.optimize(objective, n_trials=10)\n",
    "\n",
    "\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "\n",
    "print(f\"RMSLE: {trial.value}\")\n",
    "print(\"Best hyperparameters: {}\".format(trial.params))\n",
    "\n",
    "# Koulutetaan paras malli uudelleen koko datasetillä\n",
    "best_params = trial.params\n",
    "dtrain = xgb.DMatrix(X_train_XGB, label=y_train, feature_names= NN_names)\n",
    "final_model = xgb.train(best_params, dtrain)\n",
    "\n",
    "dtest = xgb.DMatrix(X_test_XGB, label=y_test, feature_names=NN_names)\n",
    "\n",
    "predictions_XGB = final_model.predict(dtest)\n",
    "mse = mean_squared_error(y_test, predictions_XGB)\n",
    "mae = mean_absolute_error(y_test, predictions_XGB)\n",
    "r2 = r2_score(y_test, predictions_XGB)\n",
    "rmsle_val = rmsle(y_test, predictions_XGB)  \n",
    "\n",
    "print(f\"Parhaan mallin tulokset testidatalla:\")\n",
    "print(f\"MAE: {mae}, MSE: {mse}, R2: {r2}, RMSLE: {rmsle_val}\")\n",
    "print(f'Time taken for XGBoost optimization: {str(timedelta(seconds=(time.time() - time_xgb)))}')\n",
    "\n",
    "# Visualisoidaan ennustettuja arvoja verrattuna todellisiin arvoihin\n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.scatter(y_test, predictions_XGB, edgecolors=(0, 0, 0))\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--', lw=4)\n",
    "plt.xlabel('Measured')\n",
    "plt.ylabel('Predicted')\n",
    "plt.title('Measured vs. Predicted Values')\n",
    "plt.show()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20, 30))\n",
    "xgb.plot_importance(final_model, importance_type='weight', ax=ax)\n",
    "ax.set_title('Feature Importance by Weight', fontsize=16)\n",
    "plt.show()\n",
    "\n",
    "# Asetetaan toisen kuvaajan koko\n",
    "fig, ax = plt.subplots(figsize=(20, 30))\n",
    "xgb.plot_importance(final_model, importance_type='gain', ax=ax)\n",
    "ax.set_title('Feature Importance by Gain', fontsize=16)\n",
    "plt.show()\n",
    "\n",
    "# Asetetaan kolmannen kuvaajan koko\n",
    "fig, ax = plt.subplots(figsize=(20, 30))\n",
    "xgb.plot_importance(final_model, importance_type='cover', ax=ax)\n",
    "ax.set_title('Feature Importance by Cover', fontsize=16)\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "joda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
