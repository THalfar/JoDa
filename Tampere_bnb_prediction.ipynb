{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d44bd9f2",
   "metadata": {},
   "source": [
    "# TampereBNB Listings - Price Prediction\n",
    "<p> Get ready for an exhilarating data science adventure! In this exciting assignment, you will dive into the world of TampereBNB, the popular platform for short-term accommodation rentals. \n",
    "    <br>\n",
    "    Your mission? To analyze data from this platform and use your data science skills to predict missing prices for some of the listings, using the tools mentioned in the following cell. </p>\n",
    "<br>\n",
    "\n",
    "## Instructions\n",
    "- Train a regression model of your choice on predicting the listing prices of the training data. \n",
    "- Use the trained model to get the price predictions for the listings in the testing data.\n",
    "- Store the resulting dataframe as a pickled (out.pkl) file. \n",
    "\n",
    "**NOTE: The code snippets for loading the data files and outputting the resulting dataframe, are provided. Do not update them.**\n",
    "\n",
    "\n",
    "#### Accessing the dataset\n",
    "To facilitate your work, we have created two separate training and testing TampereBNB csv files, located within the `data/` folder. Make sure the path to the files is the same, before submitting your solution.\n",
    "\n",
    "#### TODO\n",
    "\n",
    "- You are expected to predict prices for the listings on the testing data by using the following libraries (Besides the built-in python modules, specific libraries can be included upon request):\n",
    "    - scikit-learn (sklearn)\n",
    "    - pandas\n",
    "    - numpy\n",
    "    \n",
    "- Store your predictions as a dataframe with the attribute `Hinta` (case sensitive).\n",
    "- Save the dataframe in a pickle file, `out.pkl` (case sensitive).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "827a6736-b034-4917-ba6b-307c8ee7e2e0",
   "metadata": {},
   "source": [
    "## Importing the required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "319c09fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import numpy as np\n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "852b0df0",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "617b703b-c52a-475a-95b2-4b04a05f4fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !MAKE SURE TO NOT CHANGE THE CODE WITHIN THIS CELL!. \n",
    "# Instead, put the data files within a folder named 'data' such that the paths would work.\n",
    "training_df = pd.read_csv('./data/Tampere_BNB_training_listing.csv')\n",
    "testing_df = pd.read_csv('./data/Tampere_BNB_testing_listing.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "80621696-0dd5-4484-a08b-a61939612717",
   "metadata": {},
   "outputs": [],
   "source": [
    "# POISTA!\n",
    "pd.set_option('display.max_row', None) \n",
    "pd.set_option('display.max_columns', None) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "40eceafc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Kaupunginosa</th>\n",
       "      <th>Huoneisto</th>\n",
       "      <th>Talot.</th>\n",
       "      <th>m2</th>\n",
       "      <th>Rv</th>\n",
       "      <th>Krs</th>\n",
       "      <th>Hissi</th>\n",
       "      <th>Kunto</th>\n",
       "      <th>Asunnon tyyppi</th>\n",
       "      <th>Pituusaste</th>\n",
       "      <th>Leveysaste</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Kaleva</td>\n",
       "      <td>2h, k, rt, kph,...</td>\n",
       "      <td>kt</td>\n",
       "      <td>56.0</td>\n",
       "      <td>1956</td>\n",
       "      <td>3/4</td>\n",
       "      <td>on</td>\n",
       "      <td>tyyd.</td>\n",
       "      <td>Kaksi huonetta</td>\n",
       "      <td>23.805462</td>\n",
       "      <td>61.496083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Keskusta</td>\n",
       "      <td>2h,kk,s</td>\n",
       "      <td>kt</td>\n",
       "      <td>56.0</td>\n",
       "      <td>1908</td>\n",
       "      <td>NaN</td>\n",
       "      <td>on</td>\n",
       "      <td>hyvä</td>\n",
       "      <td>Kaksi huonetta</td>\n",
       "      <td>24.064453</td>\n",
       "      <td>61.468052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hämeenpuisto</td>\n",
       "      <td>4-5 h,avok,2xkp...</td>\n",
       "      <td>kt</td>\n",
       "      <td>184.0</td>\n",
       "      <td>1928</td>\n",
       "      <td>3/6</td>\n",
       "      <td>on</td>\n",
       "      <td>hyvä</td>\n",
       "      <td>Neljä huonetta tai enemmän</td>\n",
       "      <td>23.751403</td>\n",
       "      <td>61.492285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Viinikka</td>\n",
       "      <td>3h, k, kph, p</td>\n",
       "      <td>kt</td>\n",
       "      <td>65.0</td>\n",
       "      <td>1956</td>\n",
       "      <td>2/2</td>\n",
       "      <td>ei</td>\n",
       "      <td>hyvä</td>\n",
       "      <td>Kolme huonetta</td>\n",
       "      <td>23.786301</td>\n",
       "      <td>61.489502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Leinola</td>\n",
       "      <td>4 h + k + s + w...</td>\n",
       "      <td>ok</td>\n",
       "      <td>112.0</td>\n",
       "      <td>1978</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ei</td>\n",
       "      <td>hyvä</td>\n",
       "      <td>Neljä huonetta tai enemmän</td>\n",
       "      <td>23.914912</td>\n",
       "      <td>61.490368</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Kaupunginosa           Huoneisto Talot.     m2    Rv  Krs Hissi  Kunto  \\\n",
       "0        Kaleva  2h, k, rt, kph,...     kt   56.0  1956  3/4    on  tyyd.   \n",
       "1      Keskusta             2h,kk,s     kt   56.0  1908  NaN    on   hyvä   \n",
       "2  Hämeenpuisto  4-5 h,avok,2xkp...     kt  184.0  1928  3/6    on   hyvä   \n",
       "3      Viinikka       3h, k, kph, p     kt   65.0  1956  2/2    ei   hyvä   \n",
       "4       Leinola  4 h + k + s + w...     ok  112.0  1978  NaN    ei   hyvä   \n",
       "\n",
       "               Asunnon tyyppi  Pituusaste  Leveysaste  \n",
       "0              Kaksi huonetta   23.805462   61.496083  \n",
       "1              Kaksi huonetta   24.064453   61.468052  \n",
       "2  Neljä huonetta tai enemmän   23.751403   61.492285  \n",
       "3              Kolme huonetta   23.786301   61.489502  \n",
       "4  Neljä huonetta tai enemmän   23.914912   61.490368  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "276a6f7f",
   "metadata": {},
   "source": [
    "## Data Cleaning (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "badd76c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c3441433",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "training_df['Rv'] = training_df['Rv'].astype(int)\n",
    "testing_df['Rv'] = testing_df['Rv'].astype(int)\n",
    "\n",
    "training_df['Kunto'] = training_df['Kunto'].fillna('Ei tietoa')\n",
    "testing_df['Kunto'] = testing_df['Kunto'].fillna('Ei tietoa')\n",
    "\n",
    "kunto_mappaus = {\n",
    "    'Ei tietoa': 0,\n",
    "    'huono': 1,\n",
    "    'tyyd.': 2,\n",
    "    'hyvä': 3,\n",
    "}\n",
    "training_df['Kunto'] = training_df['Kunto'].map(kunto_mappaus)\n",
    "testing_df['Kunto'] = testing_df['Kunto'].map(kunto_mappaus)\n",
    "\n",
    "le_kunto = LabelEncoder()\n",
    "le_kunto.fit(list(training_df['Kunto'].values) + list(testing_df['Kunto'].values))\n",
    "training_df['Kunto'] = le_kunto.transform(training_df['Kunto'])\n",
    "testing_df['Kunto'] = le_kunto.transform(testing_df['Kunto'])\n",
    "\n",
    "training_df['Hissi'] = training_df['Hissi'].astype('category')\n",
    "training_df['Hissi'] = training_df['Hissi'].cat.codes\n",
    "\n",
    "testing_df['Hissi'] = testing_df['Hissi'].astype('category')\n",
    "testing_df['Hissi'] = testing_df['Hissi'].cat.codes\n",
    "\n",
    "le_kaupunginosa = LabelEncoder()\n",
    "\n",
    "training_df['Kaupunginosa'] = training_df['Kaupunginosa'].astype('category')   \n",
    "testing_df['Kaupunginosa'] = testing_df['Kaupunginosa'].astype('category')\n",
    "\n",
    "raja_arvo = 0.01\n",
    "maarat = training_df['Kaupunginosa'].value_counts(normalize=True)\n",
    "pienet_ryhmat = maarat[maarat < raja_arvo].index\n",
    "training_df['Kaupunginosa'] = training_df['Kaupunginosa'].replace(pienet_ryhmat, 'Muu')\n",
    "\n",
    "maarat = testing_df['Kaupunginosa'].value_counts(normalize=True)\n",
    "pienet_ryhmat = maarat[maarat < raja_arvo].index\n",
    "testing_df['Kaupunginosa'] = testing_df['Kaupunginosa'].replace(pienet_ryhmat, 'Muu')\n",
    "\n",
    "training_df['Kaupunginosa'] = training_df['Kaupunginosa'].astype('category')\n",
    "training_df['Kaupunginosa'] = training_df['Kaupunginosa'].cat.codes\n",
    "\n",
    "testing_df['Kaupunginosa'] = testing_df['Kaupunginosa'].astype('category')\n",
    "testing_df['Kaupunginosa'] = testing_df['Kaupunginosa'].cat.codes\n",
    "\n",
    "le_kaupunginosa.fit(list(training_df['Kaupunginosa'].values) + list(testing_df['Kaupunginosa'].values))\n",
    "training_df['Kaupunginosa'] = le_kaupunginosa.transform(training_df['Kaupunginosa'])\n",
    "testing_df['Kaupunginosa'] = le_kaupunginosa.transform(testing_df['Kaupunginosa'])\n",
    "\n",
    "le_asunnontyyppi = LabelEncoder()\n",
    "\n",
    "tyyppimat = {\n",
    "    'Yksiö' : 1,\n",
    "    'Kaksi huonetta' : 2,\n",
    "    'Kolme huonetta' : 3,\n",
    "    'Neljä huonetta tai enemmän' : 4\n",
    "}\n",
    "training_df['Asunnon tyyppi'] = training_df['Asunnon tyyppi'].map(tyyppimat)\n",
    "testing_df['Asunnon tyyppi'] = testing_df['Asunnon tyyppi'].map(tyyppimat)\n",
    "\n",
    "le_asunnontyyppi.fit(list(training_df['Asunnon tyyppi'].values) + list(testing_df['Asunnon tyyppi'].values))\n",
    "training_df['Asunnon tyyppi'] = le_asunnontyyppi.transform(training_df['Asunnon tyyppi'])\n",
    "testing_df['Asunnon tyyppi'] = le_asunnontyyppi.transform(testing_df['Asunnon tyyppi'])\n",
    "\n",
    "\n",
    "training_df['Huoneisto'] = training_df['Huoneisto'].str.lower()\n",
    "training_df['Huoneisto'] = training_df['Huoneisto'].str.replace(' ', '')\n",
    "training_df['Huoneisto'] = training_df['Huoneisto'].str.replace('+', ',')\n",
    "training_df['Huoneisto'] = training_df['Huoneisto'].str.replace('...', \"\")\n",
    "\n",
    "testing_df['Huoneisto'] = testing_df['Huoneisto'].str.lower()\n",
    "testing_df['Huoneisto'] = testing_df['Huoneisto'].str.replace(' ', '')\n",
    "testing_df['Huoneisto'] = testing_df['Huoneisto'].str.replace('+', ',')\n",
    "testing_df['Huoneisto'] = testing_df['Huoneisto'].str.replace('...', \"\")\n",
    "\n",
    "training_df['Huoneisto'] = training_df['Huoneisto'].str.replace('/', ',')\n",
    "training_df['Huoneisto'] = training_df['Huoneisto'].str.replace('[0-9]+h', '', regex=True)\n",
    "\n",
    "testing_df['Huoneisto'] = testing_df['Huoneisto'].str.replace('/', ',')\n",
    "testing_df['Huoneisto'] = testing_df['Huoneisto'].str.replace('[0-9]+h', '', regex=True)\n",
    "\n",
    "training_df['Huoneisto'] = training_df['Huoneisto'].str.replace('^,', '',regex=True)\n",
    "training_df['Huoneisto'] = training_df['Huoneisto'].str.replace('^[-0-9]+', '',regex=True)\n",
    "training_df['Huoneisto'] = training_df['Huoneisto'].str.replace(',$', '',regex=True)\n",
    "training_df['Huoneisto'] = training_df['Huoneisto'].str.replace('^,', '',regex=True)\n",
    "\n",
    "testing_df['Huoneisto'] = testing_df['Huoneisto'].str.replace('^,', '',regex=True)\n",
    "testing_df['Huoneisto'] = testing_df['Huoneisto'].str.replace('^[-0-9]+', '',regex=True)\n",
    "testing_df['Huoneisto'] = testing_df['Huoneisto'].str.replace(',$', '',regex=True)\n",
    "testing_df['Huoneisto'] = testing_df['Huoneisto'].str.replace('^,', '',regex=True)\n",
    "\n",
    "huoneisto_split = training_df['Huoneisto'].str.split(',')\n",
    "huoneisto_split = huoneisto_split.apply(lambda lst: [\"parveke\" if  re.search('^p$|^parv$', item) else item for item in lst])\n",
    "huoneisto_split = huoneisto_split.apply(lambda lst: [\"wc\" if  re.search('^w$', item) else item for item in lst])\n",
    "huoneisto_split = huoneisto_split.apply(lambda lst: [\"sauna\" if  re.search('^s$', item) else item for item in lst])\n",
    "huoneisto_split = huoneisto_split.apply(lambda lst: [\"2wc\" if  re.search('^erill.wc$|^2xwc$', item) else item for item in lst])\n",
    "huoneisto_split = huoneisto_split.apply(lambda lst: [\"kph\" if  re.search('^kh$', item) else item for item in lst])\n",
    "huoneisto_split = huoneisto_split.apply(lambda lst: [\"alkovi\" if  re.search('^alk$', item) else item for item in lst])\n",
    "huoneisto_split = huoneisto_split.apply(lambda lst: [\"lasit\" if  re.search('^l', item) else item for item in lst])\n",
    "huoneisto_split = huoneisto_split.apply(lambda lst: [\"avok\" if  re.search('^avokeitti&#$', item) else item for item in lst])\n",
    "\n",
    "exploded = huoneisto_split.explode()\n",
    "exploded_lkm = exploded.value_counts()\n",
    "\n",
    "minimi_lkm = 10\n",
    "suodatetut_idx = exploded_lkm[exploded_lkm >= minimi_lkm].index\n",
    "suodatettu_lista = huoneisto_split.apply(lambda lst: [item for item in lst if item in suodatetut_idx])\n",
    "suodatettu_lista = suodatettu_lista.apply(lambda lst: [\"määrittämätön\"] if len(lst) == 0 else lst)\n",
    "\n",
    "training_df['Huoneisto'] = suodatettu_lista.apply(lambda lst: ','.join(lst))\n",
    "\n",
    "training_encoded = training_df['Huoneisto'].str.get_dummies(sep=',')\n",
    "\n",
    "\n",
    "huoneisto_split = testing_df['Huoneisto'].str.split(',')\n",
    "huoneisto_split = huoneisto_split.apply(lambda lst: [\"parveke\" if  re.search('^p$|^parv$', item) else item for item in lst])\n",
    "huoneisto_split = huoneisto_split.apply(lambda lst: [\"wc\" if  re.search('^w$', item) else item for item in lst])\n",
    "huoneisto_split = huoneisto_split.apply(lambda lst: [\"sauna\" if  re.search('^s$', item) else item for item in lst])\n",
    "huoneisto_split = huoneisto_split.apply(lambda lst: [\"2wc\" if  re.search('^erill.wc$|^2xwc$', item) else item for item in lst])\n",
    "huoneisto_split = huoneisto_split.apply(lambda lst: [\"kph\" if  re.search('^kh$', item) else item for item in lst])\n",
    "huoneisto_split = huoneisto_split.apply(lambda lst: [\"alkovi\" if  re.search('^alk$', item) else item for item in lst])\n",
    "huoneisto_split = huoneisto_split.apply(lambda lst: [\"lasit\" if  re.search('^l', item) else item for item in lst])\n",
    "huoneisto_split = huoneisto_split.apply(lambda lst: [\"avok\" if  re.search('^avokeitti&#$', item) else item for item in lst])\n",
    "\n",
    "exploded = huoneisto_split.explode()\n",
    "exploded_lkm = exploded.value_counts()\n",
    "\n",
    "minimi_lkm = 10\n",
    "suodatetut_idx = exploded_lkm[exploded_lkm >= minimi_lkm].index\n",
    "suodatettu_lista = huoneisto_split.apply(lambda lst: [item for item in lst if item in suodatetut_idx])\n",
    "suodatettu_lista = suodatettu_lista.apply(lambda lst: [\"määrittämätön\"] if len(lst) == 0 else lst)\n",
    "\n",
    "testing_df['Huoneisto'] = suodatettu_lista.apply(lambda lst: ','.join(lst))\n",
    "\n",
    "testing_encoded = testing_df['Huoneisto'].str.get_dummies(sep=',')\n",
    "\n",
    "#  Varmista, että molemmat data frame -rakenteet sisältävät samat sarakkeet\n",
    "missing_cols = set(training_encoded.columns) - set(testing_encoded.columns)\n",
    "for c in missing_cols:\n",
    "    testing_encoded[c] = 0\n",
    "\n",
    "# Varmista myös, että testidata sisältää kaikki koulutusdatan sarakkeet\n",
    "missing_cols = set(testing_encoded.columns) - set(training_encoded.columns)\n",
    "for c in missing_cols:\n",
    "    training_encoded[c] = 0\n",
    "\n",
    "# Järjestä sarakkeet varmistaaksesi saman järjestyksen\n",
    "training_encoded = training_encoded.reindex(sorted(training_encoded.columns), axis=1)\n",
    "testing_encoded = testing_encoded.reindex(sorted(testing_encoded.columns), axis=1)\n",
    "\n",
    "# Yhdistä alkuperäiseen DataFrameen\n",
    "training_df = pd.concat([training_df.drop(['Huoneisto'], axis=1), training_encoded], axis=1)\n",
    "testing_df = pd.concat([testing_df.drop(['Huoneisto'], axis=1), testing_encoded], axis=1)\n",
    "\n",
    "le_talot = LabelEncoder()\n",
    "\n",
    "\n",
    "training_df[\"Talot.\"] = training_df[\"Talot.\"].astype('category')\n",
    "testing_df[\"Talot.\"] = testing_df[\"Talot.\"].astype('category')\n",
    "\n",
    "le_talot.fit(list(training_df['Talot.'].values) + list(testing_df['Talot.'].values))\n",
    "training_df['Talot.'] = le_talot.transform(training_df['Talot.'])\n",
    "testing_df['Talot.'] = le_talot.transform(testing_df['Talot.'])\n",
    "\n",
    "\n",
    "training_df[\"Krs\"] = training_df[\"Krs\"].fillna(\"0/0\")\n",
    "testing_df[\"Krs\"] = testing_df[\"Krs\"].fillna(\"0/0\")\n",
    "\n",
    "training_df[\"Krs\"] = training_df[\"Krs\"].str.replace('^-', '', regex=True)\n",
    "testing_df[\"Krs\"] = testing_df[\"Krs\"].str.replace('^-', '', regex=True)\n",
    "\n",
    "kerros_split = training_df[\"Krs\"].str.split('/', expand=True)  \n",
    "training_df[\"kerros\"] = kerros_split[0].astype(int)\n",
    "training_df[\"max_kerros\"] = kerros_split[1].astype(int)    \n",
    "\n",
    "kerros_split = testing_df[\"Krs\"].str.split('/', expand=True)\n",
    "testing_df[\"kerros\"] = kerros_split[0].astype(int)\n",
    "testing_df[\"max_kerros\"] = kerros_split[1].astype(int)\n",
    "\n",
    "training_df.drop(['Krs'], axis=1, inplace=True)\n",
    "testing_df.drop(['Krs'], axis=1, inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7655261-b358-4e1d-a746-758704421eb2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b75480dc-8ad4-4fd3-bdbc-fc906926af3c",
   "metadata": {},
   "source": [
    "## Feature Engineering (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "321dbb26-2549-436b-82ad-712fe41bea9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature engineering/extraction/discovery to extract features new from the raw data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb4358c-864e-410c-935d-244acc5c72a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "76b9c136-891d-4b77-a45e-4466dba98153",
   "metadata": {},
   "source": [
    "## Data Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fc9144c7-d090-44e7-9ed8-82875c3e205c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error: 516.697515\n",
      "Mean absolute error: 12.586\n",
      "R2 score: 0.9739523219558454\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "\n",
    "reg = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "reg.fit(training_df.drop('Hinta', axis=1), training_df['Hinta'])\n",
    "\n",
    "pred = reg.predict(training_df.drop('Hinta', axis=1))\n",
    "\n",
    "print(f\"Mean squared error: {mean_squared_error(training_df['Hinta'], pred)}\")\n",
    "print(f'Mean absolute error: {mean_absolute_error(training_df[\"Hinta\"], pred)}')    \n",
    "print(f'R2 score: {r2_score(training_df[\"Hinta\"], pred)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7c9c6bbf-0be4-4594-9b76-74109c7698bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure to store your predictions in the 'Hinta' attribute of the testing dataframe.\n",
    "\n",
    "pred_testing = reg.predict(testing_df)\n",
    "\n",
    "testing_df['Hinta'] = pred_testing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f4272e4-06c7-49b5-b7cd-977a3965ba8b",
   "metadata": {},
   "source": [
    "## Store the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "06c9bac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !MAKE SURE TO NOT CHANGE THE CODE WITHIN THIS CELL!. \n",
    "testing_df.to_pickle(\"out.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
