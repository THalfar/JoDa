{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os \n",
    "import seaborn as sns\n",
    "\n",
    "hakemisto = './data/'\n",
    "\n",
    "sisalto = os.listdir(hakemisto)\n",
    "print(sisalto)\n",
    "\n",
    "# Ladataan data \n",
    "df_train = pd.read_csv('./data/Tampere_BNB_training_listing.csv')\n",
    "df_test = pd.read_csv('./data/Tampere_BNB_testing_listing.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "puuttuvat_arvot = df_train.isnull().sum()\n",
    "puuttuvat_arvot = puuttuvat_arvot[puuttuvat_arvot > 0]\n",
    "print(f\"Puuttuvat arvot:\\n {puuttuvat_arvot}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "puuttuvat_arvot_prosentteina = (puuttuvat_arvot / len(df_train)) * 100\n",
    "print(f\"Puuttuvat arvot prosentteina:\\n {puuttuvat_arvot_prosentteina}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "puuttuvat_arvot_prosentteina = puuttuvat_arvot_prosentteina.sort_values() # Järjestellään kasvavaan järjestykseen\n",
    "\n",
    "# Visualisointi \n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "plt.figure(figsize=(10, 15))  # Säädä kokoa tarpeen mukaan\n",
    "sns.barplot(x=puuttuvat_arvot_prosentteina, y=puuttuvat_arvot_prosentteina.index)\n",
    "plt.title('Puuttuvien arvojen prosenttiosuus sarakkeittain')\n",
    "plt.xlabel('Prosenttiosuus (%)')\n",
    "plt.ylabel('Sarakkeet')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Muutetaan Rv sarakkeen tyyppi kokonaisluvuksi\n",
    "df_train['Rv'] = df_train['Rv'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['Rv'].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['Rv'].value_counts().sort_index().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['Kunto'] = df_train['Kunto'].fillna('Ei tietoa')\n",
    "df_train['Kunto'].value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kunto_mappaus = {\n",
    "    'Ei tietoa': 0,\n",
    "    'huono': 1,\n",
    "    'tyyd.': 2,\n",
    "    'hyvä': 3,\n",
    "}\n",
    "df_train['Kunto'] = df_train['Kunto'].map(kunto_mappaus)\n",
    "df_train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['Kunto'].value_counts()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['Hissi'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['Hissi'] = df_train['Hissi'].astype('category')\n",
    "df_train['Hissi'] = df_train['Hissi'].cat.codes\n",
    "df_train['Hissi'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_row', None) \n",
    "pd.set_option('display.max_columns', None) \n",
    "df_train['Kaupunginosa'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['Kaupunginosa'] = df_train['Kaupunginosa'].astype('category')   \n",
    "df_train['Kaupunginosa'].value_counts().plot(kind='bar') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raja_arvo = 0.01\n",
    "maarat = df_train['Kaupunginosa'].value_counts(normalize=True)\n",
    "pienet_ryhmat = maarat[maarat < raja_arvo].index\n",
    "df_train['Kaupunginosa'] = df_train['Kaupunginosa'].replace(pienet_ryhmat, 'Muu')\n",
    "df_train['Kaupunginosa'].value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['Kaupunginosa'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['Kaupunginosa'] = df_train['Kaupunginosa'].astype('category')\n",
    "df_train['Kaupunginosa'] = df_train['Kaupunginosa'].cat.codes\n",
    "df_train['Kaupunginosa'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['Asunnon tyyppi'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tyyppimat = {\n",
    "    'Yksiö' : 1,\n",
    "    'Kaksi huonetta' : 2,\n",
    "    'Kolme huonetta' : 3,\n",
    "    'Neljä huonetta tai enemmän' : 4\n",
    "}\n",
    "df_train['Asunnon tyyppi'] = df_train['Asunnon tyyppi'].map(tyyppimat)\n",
    "df_train['Asunnon tyyppi'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['Huoneisto'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['Huoneisto'] = df_train['Huoneisto'].str.lower()\n",
    "df_train['Huoneisto'] = df_train['Huoneisto'].str.replace(' ', '')\n",
    "df_train['Huoneisto'] = df_train['Huoneisto'].str.replace('+', ',')\n",
    "df_train['Huoneisto'] = df_train['Huoneisto'].str.replace('...', \"\")\n",
    "df_train['Huoneisto'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['Huoneisto'] = df_train['Huoneisto'].str.replace('/', ',')\n",
    "df_train['Huoneisto'] = df_train['Huoneisto'].str.replace('[0-9]+h', '', regex=True)\n",
    "df_train['Huoneisto'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['Huoneisto'] = df_train['Huoneisto'].str.replace('^,', '',regex=True)\n",
    "df_train['Huoneisto'] = df_train['Huoneisto'].str.replace('^[-0-9]+', '',regex=True)\n",
    "df_train['Huoneisto'] = df_train['Huoneisto'].str.replace(',$', '',regex=True)\n",
    "df_train['Huoneisto'] = df_train['Huoneisto'].str.replace('^,', '',regex=True)\n",
    "df_train['Huoneisto'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "huoneisto_split = df_train['Huoneisto'].str.split(',')\n",
    "exploded = huoneisto_split.explode()\n",
    "# exploded_unique = exploded.nunique()\n",
    "exploded_unique_count = exploded.value_counts()\n",
    "print(f\"Unique values: {exploded_unique_count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Käytetään wikisivustoa https://fi.wikipedia.org/wiki/Luettelo_asuntokaupassa_k%C3%A4ytett%C3%A4vist%C3%A4_lyhenteist%C3%A4 termeille \n",
    "\n",
    "import re\n",
    "\n",
    "huoneisto_split = df_train['Huoneisto'].str.split(',')\n",
    "\n",
    "huoneisto_split = huoneisto_split.apply(lambda lst: [\"parveke\" if  re.search('^p$|^parv$', item) else item for item in lst])\n",
    "huoneisto_split = huoneisto_split.apply(lambda lst: [\"wc\" if  re.search('^w$', item) else item for item in lst])\n",
    "huoneisto_split = huoneisto_split.apply(lambda lst: [\"sauna\" if  re.search('^s$', item) else item for item in lst])\n",
    "huoneisto_split = huoneisto_split.apply(lambda lst: [\"2wc\" if  re.search('^erill.wc$|^2xwc$', item) else item for item in lst])\n",
    "huoneisto_split = huoneisto_split.apply(lambda lst: [\"kph\" if  re.search('^kh$', item) else item for item in lst])\n",
    "huoneisto_split = huoneisto_split.apply(lambda lst: [\"alkovi\" if  re.search('^alk$', item) else item for item in lst])\n",
    "huoneisto_split = huoneisto_split.apply(lambda lst: [\"lasit\" if  re.search('^l', item) else item for item in lst])\n",
    "huoneisto_split = huoneisto_split.apply(lambda lst: [\"avok\" if  re.search('^avokeitti&#$', item) else item for item in lst])\n",
    "\n",
    "\n",
    "exploded = huoneisto_split.explode()\n",
    "exploded_lkm = exploded.value_counts()\n",
    "print(f\"Unique values: {exploded_lkm}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minimi_lkm = 10\n",
    "suodatetut_idx = exploded_lkm[exploded_lkm >= minimi_lkm].index\n",
    "suodatettu_lista = huoneisto_split.apply(lambda lst: [item for item in lst if item in suodatetut_idx])\n",
    "suodatettu_lista = suodatettu_lista.apply(lambda lst: [\"määrittämätön\"] if len(lst) == 0 else lst)\n",
    "\n",
    "df_train['Huoneisto'] = suodatettu_lista.apply(lambda lst: ','.join(lst))\n",
    "\n",
    "# Tarkistetaan vielä vähän tymästi, että onko kaikki kunnossa\n",
    "huoneisto_split = df_train['Huoneisto'].str.split(',')\n",
    "exploded = huoneisto_split.explode()\n",
    "exploded_lkm = exploded.value_counts()\n",
    "print(f\"Uniikit arvot values: {exploded_lkm}\")\n",
    "print(f\"Määrä arvot: {exploded_lkm.count()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['Huoneisto'].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_train.shape)\n",
    "# Splitataan 'Huoneisto' -sarake ja muunnetaan se listaksi pilkun perusteella\n",
    "split_data = df_train['Huoneisto'].str.split(',')\n",
    "\n",
    "# Käytetään explode()-metodia muuntaaksemme listan elementit omiksi riveikseen\n",
    "exploded_data = split_data.explode()\n",
    "\n",
    "# Valinnainen: Suodatetaan pois harvinaiset kategoriat ennen one-hot-enkoodausta\n",
    "# value_counts = exploded_data.value_counts()\n",
    "# to_keep = value_counts[value_counts >= 5].index\n",
    "# filtered_data = exploded_data[exploded_data.isin(to_keep)]\n",
    "\n",
    "# Suoritetaan one-hot-enkoodaus\n",
    "one_hot_encoded = pd.get_dummies(exploded_data)\n",
    "\n",
    "# Summataan yhteen samat rivit, koska explode() luo useita rivejä samalle alkuperäiselle indeksille\n",
    "one_hot_summed = one_hot_encoded.groupby(one_hot_encoded.index).sum()\n",
    "\n",
    "# Yhdistetään one-hot-enkoodatut sarakkeet takaisin alkuperäiseen DataFrameen\n",
    "df_train = df_train.join(one_hot_summed)\n",
    "\n",
    "print(df_train.shape)\n",
    "\n",
    "print(df_train.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[\"Talot.\"].value_counts()\n",
    "df_train[\"Talot.\"] = df_train[\"Talot.\"].astype('category')\n",
    "df_train[\"Talot.\"] = df_train[\"Talot.\"].cat.codes\n",
    "df_train[\"Talot.\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[\"Krs\"].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[\"Krs\"].isnull().sum()\n",
    "df_train[\"Krs\"] = df_train[\"Krs\"].fillna(\"0/0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[\"Krs\"] = df_train[\"Krs\"].str.replace('^-', '', regex=True)\n",
    "df_train[\"Krs\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kerros_split = df_train[\"Krs\"].str.split('/', expand=True)  \n",
    "df_train[\"kerros\"] = kerros_split[0].astype(int)\n",
    "df_train[\"max_kerros\"] = kerros_split[1].astype(int)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_filtered = df_train.drop(['Huoneisto', 'Krs'], axis=1)\n",
    "df_train_filtered.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "X = df_train_filtered.drop('Hinta', axis=1)\n",
    "y = df_train_filtered['Hinta']\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_squared_error, r2_score,  mean_absolute_error\n",
    "\n",
    "# Luodaan lineaarisen regressiomallin instanssi\n",
    "lr = LinearRegression()\n",
    "\n",
    "# Suoritetaan ristiinvalidointi\n",
    "# cv määrittää ristiinvalidoinnin jakojen määrän\n",
    "\n",
    "lr.fit(X, y)\n",
    "predictions = lr.predict(X)\n",
    "\n",
    "r2 = r2_score(y, predictions)\n",
    "mse = mean_squared_error(y, predictions)\n",
    "mae = mean_absolute_error(y, predictions)\n",
    "print(f\"Mean squared error: {mse:.2f}\\nMean absolute error: {mae:.2f}\")\n",
    "print(f\"Parhaan mallin R²-arvo: {r2}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20, 10))\n",
    "ax.scatter(y, predictions, edgecolors=(0, 0, 0))\n",
    "ax.plot([y.min(), y.max()], [y.min(), y.max()], 'k--', lw=4)\n",
    "ax.set_xlabel('Measured')\n",
    "ax.set_ylabel('Predicted')\n",
    "plt.title('Measured vs. Predicted Values')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "virhe_mallit = [xgboost.XGBRegressor(objective='reg:absoluteerror'), xgboost.XGBRegressor(objective='reg:squarederror')]\n",
    "virhe_nimi = ['neg_mean_absolute_error', 'neg_mean_squared_error']\n",
    "\n",
    "for idx, malli in enumerate(virhe_mallit):\n",
    "\n",
    "    param_space = {\n",
    "        'n_estimators': np.arange(1, 500, 10),\n",
    "        'max_depth': np.arange(3, 11),\n",
    "        'learning_rate': [0.1, 0.01, 0.001],\n",
    "        'subsample': [0.8, 0.9, 1.0],\n",
    "        'colsample_bytree': [0.8, 0.9, 1.0],\n",
    "        'gamma': [0, 1, 5],\n",
    "        'reg_alpha': [0, 0.1, 0.5],\n",
    "        'reg_lambda': [1, 1.5, 2]\n",
    "    }\n",
    "\n",
    "    random_search = RandomizedSearchCV(\n",
    "        estimator=malli,\n",
    "        param_distributions=param_space,\n",
    "        cv=10,\n",
    "        n_jobs=-2,\n",
    "        n_iter=4200, \n",
    "        verbose=1,   \n",
    "        scoring='neg_mean_absolute_error' \n",
    "    )\n",
    "\n",
    "    \n",
    "    random_search.fit(X, y)\n",
    "\n",
    "    best_index = random_search.best_index_\n",
    "    cv_results = random_search.cv_results_\n",
    "    cv_splits = random_search.cv\n",
    "    best_scores = [cv_results[f'split{i}_test_score'][best_index] for i in range(cv_splits)]\n",
    "\n",
    "\n",
    "    print(f\"With error: {virhe_nimi[idx]}\")\n",
    "    for i, score in enumerate(best_scores):\n",
    "        print(f\"Ositus {i}: {-score}\") \n",
    "\n",
    "\n",
    "    best_model = random_search.best_estimator_\n",
    "    predictions = best_model.predict(X)\n",
    "\n",
    "\n",
    "    mse = mean_squared_error(y, predictions)\n",
    "    mae = mean_absolute_error(y, predictions)\n",
    "    r2 = r2_score(y, predictions)\n",
    "    \n",
    "    print(f\"Mean squared error: {mse:.2f}\\nMean absolute error: {mae:.2f}\\nParhaan mallin R²-arvo: {r2:.4f}\")\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(20, 10))\n",
    "    ax.scatter(y, predictions, edgecolors=(0, 0, 0))\n",
    "    ax.plot([y.min(), y.max()], [y.min(), y.max()], 'k--', lw=4)\n",
    "    ax.set_xlabel('Measured')\n",
    "    ax.set_ylabel('Predicted')\n",
    "    plt.title(f'{virhe_nimi[idx]} Measured vs. Predicted Values')\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "joda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
